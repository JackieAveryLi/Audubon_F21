{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_sZfeCtDlvF5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GradCAM():\n",
    "    \"\"\"\n",
    "    Class to implement the GradCam function with it's necessary Pytorch hooks.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : detectron2 GeneralizedRCNN Model\n",
    "        A model using the detectron2 API for inferencing\n",
    "    layer_name : str\n",
    "        name of the convolutional layer to perform GradCAM with\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layer_name):\n",
    "        self.model = model\n",
    "        self.target_layer_name = target_layer_name\n",
    "        self.activations = None\n",
    "        self.gradient = None\n",
    "        self.model.eval()\n",
    "        self.activations_grads = []\n",
    "        self._register_hook()\n",
    "\n",
    "    def _get_activations_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _get_grads_hook(self, module, input_grad, output_grad):\n",
    "        self.gradient = output_grad[0]\n",
    "\n",
    "    def _register_hook(self):\n",
    "        for (name, module) in self.model.named_modules():\n",
    "            if name == self.target_layer_name:\n",
    "                self.activations_grads.append(module.register_forward_hook(self._get_activations_hook))\n",
    "                self.activations_grads.append(module.register_backward_hook(self._get_grads_hook))\n",
    "                return True\n",
    "        print(f\"Layer {self.target_layer_name} not found in Model!\")\n",
    "\n",
    "    def _release_activations_grads(self):\n",
    "      for handle in self.activations_grads:\n",
    "            handle.remove()\n",
    "    \n",
    "    def _postprocess_cam(self, raw_cam, img_width, img_height):\n",
    "        cam_orig = np.sum(raw_cam, axis=0)  # [H,W]\n",
    "        cam_orig = np.maximum(cam_orig, 0)  # ReLU\n",
    "        cam_orig -= np.min(cam_orig)\n",
    "        cam_orig /= np.max(cam_orig)\n",
    "        cam = cv2.resize(cam_orig, (img_width, img_height))\n",
    "        return cam, cam_orig\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self._release_activations_grads()\n",
    "\n",
    "    def __call__(self, inputs, target_category):\n",
    "        \"\"\"\n",
    "        Calls the GradCAM++ instance\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : dict\n",
    "            The input in the standard detectron2 model input format\n",
    "            https://detectron2.readthedocs.io/en/latest/tutorials/models.html#model-input-format\n",
    "\n",
    "        target_category : int, optional\n",
    "            The target category index. If `None` the highest scoring class will be selected\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cam : np.array()\n",
    "          Gradient weighted class activation map\n",
    "        output : list\n",
    "          list of Instance objects representing the detectron2 model output\n",
    "        \"\"\"\n",
    "        self.model.zero_grad()\n",
    "        output = self.model.forward([inputs])\n",
    "\n",
    "        if target_category == None:\n",
    "          target_category =  np.argmax(output[0]['instances'].scores.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        score = output[0]['instances'].scores[target_category]\n",
    "        #box0 = output[0]['instances'].pred_boxes[0].tensor[0][target_category]\n",
    "        #print(box0)\n",
    "        #box0.backward()\n",
    "        score.backward()\n",
    "\n",
    "        gradient = self.gradient[0].cpu().data.numpy()  # [C,H,W]\n",
    "        activations = self.activations[0].cpu().data.numpy()  # [C,H,W]\n",
    "        weight = np.mean(gradient, axis=(1, 2))  # [C]\n",
    "\n",
    "        cam = activations * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n",
    "        cam, cam_orig = self._postprocess_cam(cam, inputs[\"width\"], inputs[\"height\"])\n",
    "\n",
    "        return cam, cam_orig, output\n",
    "\n",
    "class GradCamPlusPlus(GradCAM):\n",
    "    \"\"\"\n",
    "    Subclass to implement the GradCam++ function with it's necessary PyTorch hooks.\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : detectron2 GeneralizedRCNN Model\n",
    "        A model using the detectron2 API for inferencing\n",
    "    target_layer_name : str\n",
    "        name of the convolutional layer to perform GradCAM++ with\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer_name):\n",
    "        super(GradCamPlusPlus, self).__init__(model, target_layer_name)\n",
    "\n",
    "    def __call__(self, inputs, target_category):\n",
    "        \"\"\"\n",
    "        Calls the GradCAM++ instance\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : dict\n",
    "            The input in the standard detectron2 model input format\n",
    "            https://detectron2.readthedocs.io/en/latest/tutorials/models.html#model-input-format\n",
    "\n",
    "        target_category : int, optional\n",
    "            The target category index. If `None` the highest scoring class will be selected\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cam : np.array()\n",
    "          Gradient weighted class activation map\n",
    "        output : list\n",
    "          list of Instance objects representing the detectron2 model output\n",
    "        \"\"\"\n",
    "        self.model.zero_grad()\n",
    "        output = self.model.forward([inputs])\n",
    "\n",
    "        if target_category == None:\n",
    "          target_category =  np.argmax(output[0]['instances'].scores.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        score = output[0]['instances'].scores[target_category]\n",
    "        score.backward()\n",
    "\n",
    "        gradient = self.gradient[0].cpu().data.numpy()  # [C,H,W]\n",
    "        activations = self.activations[0].cpu().data.numpy()  # [C,H,W]\n",
    "\n",
    "        #from https://github.com/jacobgil/pytorch-grad-cam/blob/master/pytorch_grad_cam/grad_cam_plusplus.py\n",
    "        grads_power_2 = gradient**2\n",
    "        grads_power_3 = grads_power_2 * gradient\n",
    "        # Equation 19 in https://arxiv.org/abs/1710.11063\n",
    "        sum_activations = np.sum(activations, axis=(1, 2))\n",
    "        eps = 0.000001\n",
    "        aij = grads_power_2 / (2 * grads_power_2 +\n",
    "                               sum_activations[:, None, None] * grads_power_3 + eps)\n",
    "        # Now bring back the ReLU from eq.7 in the paper,\n",
    "        # And zero out aijs where the activations are 0\n",
    "        aij = np.where(gradient != 0, aij, 0)\n",
    "\n",
    "        weights = np.maximum(gradient, 0) * aij\n",
    "        weight = np.sum(weights, axis=(1, 2))\n",
    "\n",
    "        cam = activations * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n",
    "        cam, cam_orig = self._postprocess_cam(cam, inputs[\"width\"], inputs[\"height\"])\n",
    "\n",
    "        return cam, cam_orig, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lZgKHsr-aTxs"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import detectron2.data.transforms as T\n",
    "import numpy as np\n",
    "import torch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class Detectron2GradCAM():\n",
    "  \"\"\"\n",
    "      Attributes\n",
    "    ----------\n",
    "    config_file : str\n",
    "        detectron2 model config file path\n",
    "    model_file : str\n",
    "        detectron2 model file path\n",
    "    \"\"\"\n",
    "  def __init__(self, config_file, model_file):\n",
    "      self.cfg = self._setup_cfg(config_file, model_file)\n",
    "\n",
    "  def _setup_cfg(self, config_file, model_file):\n",
    "      # load config from file, add your custom model config like RPN HEADS here\n",
    "      cfg = get_cfg()\n",
    "      cfg.merge_from_file(config_file)\n",
    "\n",
    "      # cfg.DATALOADER.NUM_WORKERS = cfg_parms['NUM_WORKERS']\n",
    "      # cfg.SOLVER.IMS_PER_BATCH = cfg_parms['IMS_PER_BATCH']\n",
    "      # cfg.SOLVER.BASE_LR = cfg_parms['BASE_LR']\n",
    "      # cfg.SOLVER.GAMMA = cfg_parms['GAMMA']\n",
    "      # cfg.SOLVER.WARMUP_ITERS = cfg_parms['WARMUP_ITERS']\n",
    "      cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(cfg_parms['BIRD_SPECIES'])\n",
    "      # cfg.SOLVER.MAX_ITER = cfg_parms['MAX_ITER']\n",
    "      # cfg.SOLVER.STEPS = cfg_parms['STEPS']\n",
    "      # cfg.SOLVER.CHECKPOINT_PERIOD = cfg_parms['CHECKPOINT_PERIOD']\n",
    "      # cfg.DATASETS.TRAIN = (\"birds_species_Train\",)\n",
    "\n",
    "      # cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "      # cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "      cfg.MODEL.WEIGHTS = model_file\n",
    "      cfg.MODEL.DEVICE = 'cpu'\n",
    "      # if torch.cuda.is_available():\n",
    "      #   cfg.MODEL.DEVICE = \"cuda\"\n",
    "      # else:\n",
    "      #   cfg.MODEL.DEVICE = \"cpu\"\n",
    "      cfg.freeze()\n",
    "      return cfg\n",
    "\n",
    "  def _get_input_dict(self, original_image):\n",
    "      height, width = original_image.shape[:2]\n",
    "      transform_gen = T.ResizeShortestEdge(\n",
    "          [self.cfg.INPUT.MIN_SIZE_TEST, self.cfg.INPUT.MIN_SIZE_TEST], self.cfg.INPUT.MAX_SIZE_TEST\n",
    "      )\n",
    "      image = transform_gen.get_transform(original_image).apply_image(original_image)\n",
    "      image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1)).requires_grad_(True)\n",
    "      inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "      return inputs\n",
    "\n",
    "  def get_cam(self, img, target_instance, layer_name, grad_cam_type=\"GradCAM\"):\n",
    "      \"\"\"\n",
    "      Calls the GradCAM++ instance\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      img : str\n",
    "          Path to inference image\n",
    "      target_instance : int\n",
    "          The target instance index\n",
    "      layer_name : str\n",
    "          Convolutional layer to perform GradCAM on\n",
    "      grad_cam_type : str\n",
    "          GradCAM or GradCAM++ (for multiple instances of the same object, GradCAM++ can be favorable)\n",
    "\n",
    "      Returns\n",
    "      -------\n",
    "      image_dict : dict\n",
    "        {\"image\" : <image>, \"cam\" : <cam>, \"output\" : <output>, \"label\" : <label>}\n",
    "        <image> original input image\n",
    "        <cam> class activation map resized to original image shape\n",
    "        <output> instances object generated by the model\n",
    "        <label> label of the \n",
    "      cam_orig : numpy.ndarray\n",
    "        unprocessed raw cam\n",
    "      \"\"\"\n",
    "      model = build_model(self.cfg)\n",
    "      checkpointer = DetectionCheckpointer(model)\n",
    "      checkpointer.load(self.cfg.MODEL.WEIGHTS)\n",
    "\n",
    "      image = read_image(img, format=\"BGR\")\n",
    "      input_image_dict = self._get_input_dict(image)\n",
    "\n",
    "      if grad_cam_type == \"GradCAM\":\n",
    "        grad_cam = GradCAM(model, layer_name)\n",
    "\n",
    "      elif grad_cam_type == \"GradCAM++\":\n",
    "        grad_cam = GradCamPlusPlus(model, layer_name)\n",
    "      \n",
    "      else:\n",
    "        raise ValueError('Grad CAM type not specified')\n",
    "\n",
    "      with grad_cam as cam:\n",
    "        cam, cam_orig, output = cam(input_image_dict, target_category=target_instance)\n",
    "\n",
    "      image_dict = {}\n",
    "      image_dict[\"image\"] = image\n",
    "      image_dict[\"cam\"] = cam\n",
    "      image_dict[\"output\"] = output\n",
    "      # image_dict[\"label\"] = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]).thing_classes[output[0][\"instances\"].pred_classes[target_instance]]\n",
    "      image_dict[\"label\"] = ['ROT', 'SAT', 'Unknown'][output[0][\"instances\"].pred_classes[target_instance]]\n",
    "\n",
    "      return image_dict, cam_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ml_imkmDLc3N"
   },
   "outputs": [],
   "source": [
    "cfg_parms = {'NUM_WORKERS': 0, 'IMS_PER_BATCH': 8, 'BASE_LR': .01931492350199079, 'GAMMA': 0.19953251054833593,\n",
    "                 'WARMUP_ITERS': 1, 'MAX_ITER': 1600,\n",
    "                 'STEPS': [899], 'CHECKPOINT_PERIOD': 899, 'output_dir': '/content/output',\n",
    "                 'model_name': \"faster_rcnn_R_50_FPN_1x\", 'BIRD_SPECIES': ['ROT', 'SAT'], 'Custom': False}\n",
    "\n",
    "# cfg.MODEL.WEIGHTS = \"/model_final.pth\"\n",
    "# predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kekRU8fC6DeK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\r"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2 import model_zoo\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "\n",
    "colors = {'ROT':'r','SAT':'cyan','LAGUA':'w'}\n",
    "\n",
    "\"\"\"\n",
    "choose the object instance you want to perfrom GradCAM on. It's defined by `instance = 0`\n",
    "\"\"\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "\n",
    "# img = \"/content/DJI_20220616111641_0223_12_9.JPEG\"\n",
    "img = './data/22F_new/split/Validate/20220521 - Chester Island 10k-05-11_12_5.JPEG'\n",
    "config_file = model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")\n",
    "# model_file = \"/content/model_final.pth\"\n",
    "model_file = \"./output/Training_models_terns/06_22_bay_tune_retina_2class_set_I_aug/faster_rcnn_R_50_FPN_1x-20221101-170256/model_final.pth\"\n",
    "\n",
    "layer_name = \"backbone.bottom_up.res5.2.conv3\"\n",
    "\n",
    "\n",
    "cam_extractor = Detectron2GradCAM(config_file=config_file, model_file=model_file)\n",
    "\n",
    "instance = 0 #CAM is generated per object instance, not per class!\n",
    "im_grad = {'ROT':{},'SAT':{},'LAGUA':{}}\n",
    "while True:\n",
    "    try:\n",
    "        image_dict, cam_orig = cam_extractor.get_cam(img=img, target_instance=instance, \n",
    "                                                     layer_name=layer_name, grad_cam_type=\"GradCAM++\")\n",
    "    except:\n",
    "        break\n",
    "    v = Visualizer(image_dict[\"image\"], \n",
    "                   MetadataCatalog.get(f\"birds_species_Validate\"),\n",
    "    #                MetadataCatalog.get(cam_extractor.cfg.DATASETS.TRAIN[0]), \n",
    "                   scale=1.0)\n",
    "    #out = v.draw_instance_predictions(image_dict[\"output\"][0][\"instances\"][instance].to(\"cpu\"))\n",
    "    im_grad[image_dict['label']][instance] = image_dict[\"cam\"]\n",
    "    instance += 1\n",
    "    print(instance, end='\\r')\n",
    "    \n",
    "im_cam = {k:np.array(list(grad.values())).mean(0) for k,grad in im_grad.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1,3, dpi=200, figsize=(14,8))\n",
    "\n",
    "ax = axes[-1]\n",
    "im = cv2.cvtColor(cv2.imread(img), cv2.COLOR_RGB2BGR) \n",
    "ax.imshow(im, interpolation='none')\n",
    "ax.axis('off')\n",
    "# ax.set_title(f\"Original image tile with ground truth annotations\")\n",
    "pd_csv = pd.read_csv(img.replace('JPEG','csv'))\n",
    "for bx in pd_csv.iterrows():\n",
    "    rect = patches.Rectangle((bx[1].x, bx[1].y), bx[1].width, bx[1].height, \n",
    "                             linewidth=1, edgecolor=colors[bx[1].class_id], \n",
    "                             facecolor='none', label=bx[1].class_id)\n",
    "    ax.add_patch(rect)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "ax.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "\n",
    "for i, (lab, cam) in enumerate(im_cam.items()):\n",
    "    if i > 1:\n",
    "        break\n",
    "    ax = axes[i]\n",
    "    im = cv2.cvtColor(cv2.imread(img), cv2.COLOR_RGB2BGR) \n",
    "    ax.imshow(im, interpolation='none')\n",
    "    ax.imshow(cam, cmap='jet', alpha=0.5)\n",
    "    ax.axis('off')\n",
    "#     ax.set_title(f\"CAM for class {lab}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(model_file)['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
