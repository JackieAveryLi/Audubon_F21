{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster_RCNN_DenseNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "645b0403a4fc4507b5005bb185708af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f6c47ea9c1248fd991b93bdbedf33d4",
              "IPY_MODEL_9e41b8250bf74c96ace050d9b1728a77",
              "IPY_MODEL_3202f2ce3037454cb9230702006453bd"
            ],
            "layout": "IPY_MODEL_91f247e41b5342d0b88623f91bf9bff0"
          }
        },
        "7f6c47ea9c1248fd991b93bdbedf33d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7de73598c048bdb6bed37a9940389e",
            "placeholder": "​",
            "style": "IPY_MODEL_b3b159ae0718424f8d25b295486d4225",
            "value": "Cropping files: 100%"
          }
        },
        "9e41b8250bf74c96ace050d9b1728a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf55714a5fc4a829e5e7a8685a099dc",
            "max": 87,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2637216d5524c52a7b7ad1b7e829ffc",
            "value": 87
          }
        },
        "3202f2ce3037454cb9230702006453bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87e217286464cee8e71fd002ec3fb8c",
            "placeholder": "​",
            "style": "IPY_MODEL_b55e6bb1e8064713a4a39a54cc7a1408",
            "value": " 87/87 [05:02&lt;00:00,  3.28s/it]"
          }
        },
        "91f247e41b5342d0b88623f91bf9bff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7de73598c048bdb6bed37a9940389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b159ae0718424f8d25b295486d4225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf55714a5fc4a829e5e7a8685a099dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2637216d5524c52a7b7ad1b7e829ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e87e217286464cee8e71fd002ec3fb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b55e6bb1e8064713a4a39a54cc7a1408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeca394c98ff46888311adc415e97964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5681ce5ac83459ba0bdbe7a4d69b293",
              "IPY_MODEL_73b670cf0b02477086aaf341f15ac7f0",
              "IPY_MODEL_aa5290c927a54c5aba76609dbe96eb4c"
            ],
            "layout": "IPY_MODEL_91e683eba41749108d1d0854b65741bf"
          }
        },
        "d5681ce5ac83459ba0bdbe7a4d69b293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f176a7b37254543b8873c27fcd2dc08",
            "placeholder": "​",
            "style": "IPY_MODEL_64536a69e1ab4b45be26cfde560dea6d",
            "value": "100%"
          }
        },
        "73b670cf0b02477086aaf341f15ac7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf8adcf35ba4b8ea3227de555f39f0f",
            "max": 32342954,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7e3c107a81b4f94ab18a34d55b16507",
            "value": 32342954
          }
        },
        "aa5290c927a54c5aba76609dbe96eb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df9b9e9c3954a509f2f057d5ca23409",
            "placeholder": "​",
            "style": "IPY_MODEL_6d25826b89914c8890b51e72c60aae47",
            "value": " 30.8M/30.8M [00:00&lt;00:00, 57.2MB/s]"
          }
        },
        "91e683eba41749108d1d0854b65741bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f176a7b37254543b8873c27fcd2dc08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64536a69e1ab4b45be26cfde560dea6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbf8adcf35ba4b8ea3227de555f39f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e3c107a81b4f94ab18a34d55b16507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3df9b9e9c3954a509f2f057d5ca23409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d25826b89914c8890b51e72c60aae47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import some needed libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import os, json, cv2, random\n",
        "import sys, shutil, glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage import io  \n",
        "from datetime import datetime\n",
        "from distutils.dir_util import copy_tree"
      ],
      "metadata": {
        "id": "qF5tsb-xxH4O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Detectron 2"
      ],
      "metadata": {
        "id": "9-5Ir-9yuVbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell only excecutes if you're running on Colab. \n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import drive \n",
        "  drive.mount('/gdrive/') # Mount Google Drive! \n",
        "\n",
        "  # Clone Audubon bird detection Github repo SP22 branch\n",
        "  !git clone -b SP22 https://github.com/RiceD2KLab/Audubon_F21.git\n",
        "\n",
        "  !pip install pyyaml==5.1\n",
        "\n",
        "  # This is the current pytorch version on Colab. Uncomment this if Colab changes its pytorch version\n",
        "  !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "  import torch\n",
        "  TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "  CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "  print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "  # Install detectron2 that matches the above pytorch version\n",
        "  # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "  !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "  # If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "  # exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "metadata": {
        "id": "CW47FI8iuUAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "116ae265-76d0-4aa5-8db0-ddf2ea431d80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n",
            "Cloning into 'Audubon_F21'...\n",
            "remote: Enumerating objects: 1209, done.\u001b[K\n",
            "remote: Counting objects: 100% (1209/1209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (743/743), done.\u001b[K\n",
            "remote: Total 1209 (delta 698), reused 842 (delta 434), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1209/1209), 60.42 MiB | 16.03 MiB/s, done.\n",
            "Resolving deltas: 100% (698/698), done.\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 12.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=7876848928c6513070ffdcefb3fa78f2fbe15481efe5b0b114b396461f6e41d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.9.0%2Bcu102-cp37-cp37m-linux_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 3.0 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.10.0%2Bcu102-cp37-cp37m-linux_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu102) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (1.21.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0+cu102 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0+cu102 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu102 torchvision-0.10.0+cu102\n",
            "torch:  1.9 ; cuda:  cu102\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
            "Collecting detectron2\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/detectron2-0.6%2Bcu102-cp37-cp37m-linux_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Collecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.63.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220305.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 47.5 MB/s \n",
            "\u001b[?25hCollecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting regex>=2020.1.8\n",
            "  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 52.3 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.44.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220305-py3-none-any.whl size=61214 sha256=ae26348e10ddd8e3380f8e448ee396b736d5dc87d4c41f83b0a1e3c6387a0f15\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b7/6e/43b1693d06fac3633af48db68557513b0a37ab38b0a8b798f9\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=a0a66f0935fdc20c68ef6ca730bd6449dea619cbeefa621d86e7245813cd9ea4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, toml, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu102 fvcore-0.1.5.post20220305 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.4.0 regex-2022.3.15 toml-0.10.2 typed-ast-1.5.2 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Images"
      ],
      "metadata": {
        "id": "qX2vHftZ0yFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p './data/raw'\n",
        "\n",
        "# # If downloading a public zip file\n",
        "# !pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# !gdown -q https://drive.google.com/uc?id=1zhB6_MLtvD0JCoyKYqhUx497WIvSYVUk\n",
        "# !unzip -q './1017_1.zip' -d './data/raw'\n",
        "# !gdown -q https://drive.google.com/uc?id=1clRsR5zg60FYjQ-crGx8CN88yPsUgVse\n",
        "# !unzip -q './1017_2.zip' -d './data/raw'\n",
        "# !gdown -q https://drive.google.com/uc?id=1fC4xAZJFoEccrgBhvjLMGpzLVXEcfHm6\n",
        "# !unzip -q './annotation_1017.zip' -d './data/raw'\n",
        "\n",
        "# If zip files are contained in the mounted Google Drive\n",
        "!unzip -q '/gdrive/MyDrive/1017_1.zip' -d './data/raw'\n",
        "!unzip -q '/gdrive/MyDrive/1017_2.zip' -d './data/raw'\n",
        "!unzip -q '/gdrive/MyDrive/annotation_1017.zip' -d './data/raw'"
      ],
      "metadata": {
        "id": "tEao3tio00d6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display an image"
      ],
      "metadata": {
        "id": "bDachdFO1PFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = cv2.imread(\"./data/raw/DJI_20210520121129_0616.JPG\") \n",
        "cv2_imshow(im)"
      ],
      "metadata": {
        "id": "EWUCqovy1Tcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show data statistics"
      ],
      "metadata": {
        "id": "gyFNc_gi1zbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell plots the distribution of bird species contained in the entire dataset\n",
        "data_dir = './data/raw' # data directory folder \n",
        "\n",
        "# Load CSV files \n",
        "target_data = []\n",
        "for f in glob.glob(os.path.join(data_dir,'*.bbx')): \n",
        "  target_data.append(pd.read_csv(f, header=0, \n",
        "                              names = [\"class_id\", \"class_name\", \"x\", \"y\", \"width\", \"height\"]) )\n",
        "target_data = pd.concat(target_data, axis=0, ignore_index=True)\n",
        "\n",
        "# Create table and bar plot of bird species  \n",
        "print('\\n Bird Species Distribution')\n",
        "print(target_data[\"class_name\"].value_counts())\n",
        "print('\\n')\n",
        "\n",
        "ax = target_data[\"class_name\"].value_counts().plot.bar(x=\"Bird Species\", y=\"Frequency\",figsize=(10,6))  \n",
        "ax.set_title('Bird Species Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jR8-7QWf14Fm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "9d36db83-faea-4dc3-bad0-4d75aa4ea89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Bird Species Distribution\n",
            "Mixed Tern Adult                   8641\n",
            "Laughing Gull Adult                3168\n",
            "Brown Pelican Adult                 496\n",
            "Mixed Tern Flying                   156\n",
            "Other Bird                           95\n",
            "Laughing Gull Flying                 86\n",
            "Brown Pelican - Wings Spread         29\n",
            "Trash/Debris                         23\n",
            "Great Egret/White Morph Adult        23\n",
            "Brown Pelican Juvenile               20\n",
            "Brown Pelican In Flight              17\n",
            "Brown Pelican Wings Spread           14\n",
            "Tri-Colored Heron Adult              11\n",
            "Brown Pelican Chick                   6\n",
            "Roseate Spoonbill Adult               1\n",
            "Black Crowned Night Heron Adult       1\n",
            "Name: class_name, dtype: int64\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot an image with bounding boxes"
      ],
      "metadata": {
        "id": "fr1uao6W17HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image \n",
        "from Audubon_F21.utils import plotting\n",
        "from Audubon_F21.utils.cropping import csv_to_dict \n",
        "\n",
        "annot_dict = csv_to_dict(csv_path = './data/raw/DJI_20210520121129_0616.bbx', annot_file_ext='bbx')\n",
        "annotation_lst = [list(x.values()) for x in annot_dict['bbox']]\n",
        "\n",
        "image_file = './data/raw/DJI_20210520121129_0616.JPG'\n",
        "assert os.path.exists(image_file)\n",
        "\n",
        "#Load the image\n",
        "image = Image.open(image_file)\n",
        "\n",
        "#Plot the Bounding Box\n",
        "print(\"Raw image with bounding boxes:\")\n",
        "plotting.plot_img_bbx(image, annotation_lst)"
      ],
      "metadata": {
        "id": "W-BnVgxC2FQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crop dataset"
      ],
      "metadata": {
        "id": "UTpCsU5e2Uil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Audubon_F21.utils.cropping import crop_dataset_trainer\n",
        "\n",
        "# data_dir is the path that contains both images and annotations (image: jpg; annotation: csv or bbx)\n",
        "data_dir = './data/raw' # data directory folder \n",
        "# output dir is the path where you want to output new files. Please use the folder you defined above.\n",
        "output_dir = './data/tiled'\n",
        "\n",
        "crop_dataset_trainer(data_dir, output_dir, annot_file_ext='bbx', crop_height=640, crop_width=640,\n",
        "                     sliding_size_x=600, sliding_size_y=600, compute_sliding_size=False)"
      ],
      "metadata": {
        "id": "6x2q-Vf72X1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "645b0403a4fc4507b5005bb185708af0",
            "7f6c47ea9c1248fd991b93bdbedf33d4",
            "9e41b8250bf74c96ace050d9b1728a77",
            "3202f2ce3037454cb9230702006453bd",
            "91f247e41b5342d0b88623f91bf9bff0",
            "de7de73598c048bdb6bed37a9940389e",
            "b3b159ae0718424f8d25b295486d4225",
            "4cf55714a5fc4a829e5e7a8685a099dc",
            "a2637216d5524c52a7b7ad1b7e829ffc",
            "e87e217286464cee8e71fd002ec3fb8c",
            "b55e6bb1e8064713a4a39a54cc7a1408"
          ]
        },
        "outputId": "fda228ad-6645-43d8-9cd3-545d0a5b9d89"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output directory at: ./data/tiled\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Cropping files:   0%|          | 0/87 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "645b0403a4fc4507b5005bb185708af0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset into training, validation, and test sets"
      ],
      "metadata": {
        "id": "PoClnR1F3Dos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from Audubon_F21.utils.cropping import train_val_test_split\n",
        "\n",
        "# create a new output folder for train, val, test dataset\n",
        "# create three folders under the new output folder, with name 'train', 'val', 'test'\n",
        "!mkdir -p /content/data/split\n",
        "!mkdir -p /content/data/split/train\n",
        "!mkdir -p /content/data/split/val\n",
        "!mkdir -p /content/data/split/test\n",
        "\n",
        "# specify the folder directory where you have the tiled images (output_dir of the crop_dataset() function)\n",
        "file_dir = '/content/data/tiled'\n",
        "# output_dir is the new output folder you created in the cell above\n",
        "output_dir = '/content/data/split'\n",
        "# train is a percentage, the fraction of files for training\n",
        "train_frac = 0.8\n",
        "# val is a percentage, the fraction of files for validation\n",
        "val_frac = 0.1\n",
        "# the fraction for test is default to be 1-train-val\n",
        "train_val_test_split(file_dir, output_dir, train_frac=train_frac, val_frac=val_frac)"
      ],
      "metadata": {
        "id": "bQAIC_w43J0D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show data distribution for each set"
      ],
      "metadata": {
        "id": "d_ZdIsw34T7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data directory folders \n",
        "data_dir = 'data/split'\n",
        "dirs = [d for d in os.listdir(data_dir)]\n",
        "\n",
        "# Load CSV files \n",
        "for d in dirs: \n",
        "  target_data = []\n",
        "  for f in glob.glob(os.path.join(data_dir,d,'*.csv')): \n",
        "    target_data.append(pd.read_csv(f, header=0, \n",
        "                              names = [\"class_id\", \"class_name\", \"x\", \"y\", \"width\", \"height\"]) )\n",
        "  target_data = pd.concat(target_data, axis=0, ignore_index=True)\n",
        "\n",
        "  # Visualize dataset \n",
        "  print(f'\\n {d} - Bird Species Distribution')\n",
        "  print(target_data[\"class_name\"].value_counts())\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "WCND3y6T4SS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4068f9a-c965-4b94-81ed-310af0fc2e88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " test - Bird Species Distribution\n",
            "Mixed Tern Adult                 1250\n",
            "Laughing Gull Adult               355\n",
            "Brown Pelican Adult                54\n",
            "Mixed Tern Flying                  13\n",
            "Laughing Gull Flying               10\n",
            "Other Bird                          9\n",
            "Great Egret/White Morph Adult       5\n",
            "Tri-Colored Heron Adult             2\n",
            "Brown Pelican - Wings Spread        2\n",
            "Brown Pelican In Flight             2\n",
            "Brown Pelican Juvenile              2\n",
            "Brown Pelican Chick                 1\n",
            "Brown Pelican Wings Spread          1\n",
            "Trash/Debris                        1\n",
            "Name: class_name, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            " train - Bird Species Distribution\n",
            "Mixed Tern Adult                   7275\n",
            "Laughing Gull Adult                2836\n",
            "Brown Pelican Adult                 397\n",
            "Mixed Tern Flying                   105\n",
            "Other Bird                           83\n",
            "Laughing Gull Flying                 61\n",
            "Great Egret/White Morph Adult        22\n",
            "Trash/Debris                         21\n",
            "Brown Pelican - Wings Spread         19\n",
            "Brown Pelican Juvenile               16\n",
            "Brown Pelican Wings Spread            9\n",
            "Tri-Colored Heron Adult               8\n",
            "Brown Pelican In Flight               4\n",
            "Brown Pelican Chick                   2\n",
            "Black Crowned Night Heron Adult       2\n",
            "Roseate Spoonbill Adult               1\n",
            "Name: class_name, dtype: int64\n",
            "\n",
            "\n",
            "\n",
            " val - Bird Species Distribution\n",
            "Mixed Tern Adult                 1049\n",
            "Laughing Gull Adult               356\n",
            "Brown Pelican Adult                46\n",
            "Mixed Tern Flying                  22\n",
            "Other Bird                         18\n",
            "Trash/Debris                        7\n",
            "Laughing Gull Flying                7\n",
            "Brown Pelican - Wings Spread        3\n",
            "Tri-Colored Heron Adult             2\n",
            "Brown Pelican Wings Spread          2\n",
            "Brown Pelican Juvenile              2\n",
            "Brown Pelican In Flight             1\n",
            "Brown Pelican Chick                 1\n",
            "Great Egret/White Morph Adult       1\n",
            "Name: class_name, dtype: int64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Detectron2\n"
      ],
      "metadata": {
        "id": "Gn-PzFpkzm98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "WLaKBW00vB6a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup dataloaders \n",
        "\n",
        "The following cell registers the training, validation, and testing datasets with Detectron2's dataset catalogs. Note that we register both a version that utilizes both a singular \"bird-only\" label and the bird species labels. "
      ],
      "metadata": {
        "id": "0gSqqe0H64az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See tutorial for creating a custom dataset."
      ],
      "metadata": {
        "id": "5aQMpbgl8NEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Audubon_F21.utils.dataloader import register_datasets\n",
        "\n",
        "data_dir = './data/split'\n",
        "img_ext='.JPEG'\n",
        "dirs = [os.path.join(data_dir,d) for d in os.listdir(data_dir)]\n",
        "\n",
        "# Bird species used by object detector. Species contained in dataset that are \n",
        "# not contained in this list will be categorized as an \"Unknown Bird\"\n",
        "BIRD_SPECIES = [\"Brown Pelican\", \"Laughing Gull\", \"Mixed Tern\",\n",
        "                \"Great Blue Heron\",\"Great Egret/White Morph\"]\n",
        "\n",
        "# Bounding box colors for bird species (used when plotting images)\n",
        "BIRD_SPECIES_COLORS = [(255,0,0), (255,153,51), (0, 255, 0), \n",
        "                       (0,0,255), (255, 51, 255)]\n",
        "\n",
        "register_datasets(dirs, img_ext, BIRD_SPECIES, bird_species_colors=BIRD_SPECIES_COLORS)"
      ],
      "metadata": {
        "id": "1-GjSBOd7CFi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example function for getting dictionaries of custom data\n",
        "# dataset_dicts = get_balloon_dicts(\"balloon/train\")\n",
        "# for d in random.sample(dataset_dicts, 3):\n",
        "#     img = cv2.imread(d[\"file_name\"])\n",
        "#     visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\n",
        "#     out = visualizer.draw_dataset_dict(d)\n",
        "#     cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "0OpuSDF4CQMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test on a pretrained model"
      ],
      "metadata": {
        "id": "bPkaUL9K9FyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "model_name = \"faster_rcnn_R_50_FPN_1x\"   # ResNet-50 FPN backbone\n",
        "\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{model_name}.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{model_name}.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# im = cv2.imread(\"./data/raw/DJI_20210520121129_0616.JPG\")   # will need to a cropped image\n",
        "outputs = predictor(im)"
      ],
      "metadata": {
        "id": "NEis7ZzM9C7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "print(outputs[\"instances\"].pred_classes) #### instances might not be the correct keyword\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ],
      "metadata": {
        "id": "m2QiBjU2-4uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # We can use `Visualizer` to draw the predictions on the image.\n",
        "# # Requires metadata registration\n",
        "# # For instance segmenation with Mask R-CNN, hence may not work exactly for Faster R-CNN\n",
        "# v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "# out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "# cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "CA4X4Mb5_sks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine tune a pretrained model"
      ],
      "metadata": {
        "id": "f637rt4R-rGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Audubon_F21.utils.trainer import Trainer\n",
        "\n",
        "# setup training logger \n",
        "setup_logger()\n",
        "\n",
        "model_name = \"faster_rcnn_R_50_FPN_1x\"\n",
        "\n",
        "# Create detectron2 config \n",
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{model_name}.yaml\"))\n",
        "# Get pretrained model from MS COCO\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{model_name}.yaml\")\n",
        "\n",
        "# add datasets used for training and validation \n",
        "cfg.DATASETS.TRAIN = (\"birds_species_train\",)\n",
        "cfg.DATASETS.TEST = (\"birds_species_val\",)   # val vs test?\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8   # what's a good number for 1 GPU?\n",
        "cfg.SOLVER.BASE_LR = 1e-3   # pick a good learning rate, 0.00025 is what tutorial uses\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "cfg.SOLVER.WARMUP_ITERS = 1\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES)\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = [500,]   # [] to not decay the learning rate\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "\n",
        "cfg.OUTPUT_DIR = f\"./output/multibirds_{model_name}\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# train on bird species\n",
        "trainer = Trainer(cfg)   # DefaultTrainer(cfg) if not using a custom trainer\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "q1yDo8mqtL2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "z_K_EmFbEQXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|"
      ],
      "metadata": {
        "id": "qd7kPRLaqkra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Custom Backbone"
      ],
      "metadata": {
        "id": "VygxwpjjbtVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following are three ways to create a Mask RCNN model."
      ],
      "metadata": {
        "id": "N9ZvaO0OM8bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setup_logger()\n",
        "cfg = get_cfg()"
      ],
      "metadata": {
        "id": "0nV5f0A7bs8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Model from yaml file"
      ],
      "metadata": {
        "id": "CE8Nd2mNfXjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load proper yaml config file, then\n",
        "model = build_model(cfg)"
      ],
      "metadata": {
        "id": "Vk6sQrIFfZNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Model from config with additional argument overrides"
      ],
      "metadata": {
        "id": "lZqXvn-MfHMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GeneralizedRCNN(\n",
        "  cfg,\n",
        "  roi_heads=StandardROIHeads(cfg, batch_size_per_image=666),\n",
        "  pixel_std=[57.0, 57.0, 57.0])"
      ],
      "metadata": {
        "id": "-wiw0xbNfSLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model from full explicit arguments"
      ],
      "metadata": {
        "id": "1r86VgkYfSyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GeneralizedRCNN(\n",
        "    backbone=FPN(\n",
        "        ResNet(\n",
        "            BasicStem(3, 64, norm=\"FrozenBN\"),\n",
        "            ResNet.make_default_stages(50, stride_in_1x1=True, norm=\"FrozenBN\"),\n",
        "            out_features=[\"res2\", \"res3\", \"res4\", \"res5\"],\n",
        "        ).freeze(2),\n",
        "        [\"res2\", \"res3\", \"res4\", \"res5\"],\n",
        "        256,\n",
        "        top_block=LastLevelMaxPool(),\n",
        "    ),\n",
        "    proposal_generator=RPN(\n",
        "        in_features=[\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"],\n",
        "        head=StandardRPNHead(in_channels=256, num_anchors=3),\n",
        "        anchor_generator=DefaultAnchorGenerator(\n",
        "            sizes=[[32], [64], [128], [256], [512]],\n",
        "            aspect_ratios=[0.5, 1.0, 2.0],\n",
        "            strides=[4, 8, 16, 32, 64],\n",
        "            offset=0.0,\n",
        "        ),\n",
        "        anchor_matcher=Matcher([0.3, 0.7], [0, -1, 1], allow_low_quality_matches=True),\n",
        "        box2box_transform=Box2BoxTransform([1.0, 1.0, 1.0, 1.0]),\n",
        "        batch_size_per_image=256,\n",
        "        positive_fraction=0.5,\n",
        "        pre_nms_topk=(2000, 1000),\n",
        "        post_nms_topk=(1000, 1000),\n",
        "        nms_thresh=0.7,\n",
        "    ),\n",
        "    roi_heads=StandardROIHeads(\n",
        "        num_classes=80,\n",
        "        batch_size_per_image=512,\n",
        "        positive_fraction=0.25,\n",
        "        proposal_matcher=Matcher([0.5], [0, 1], allow_low_quality_matches=False),\n",
        "        box_in_features=[\"p2\", \"p3\", \"p4\", \"p5\"],\n",
        "        box_pooler=ROIPooler(7, (1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32), 0, \"ROIAlignV2\"),\n",
        "        box_head=FastRCNNConvFCHead(\n",
        "            ShapeSpec(channels=256, height=7, width=7), conv_dims=[], fc_dims=[1024, 1024]\n",
        "        ),\n",
        "        box_predictor=FastRCNNOutputLayers(\n",
        "            ShapeSpec(channels=1024),\n",
        "            test_score_thresh=0.05,\n",
        "            box2box_transform=Box2BoxTransform((10, 10, 5, 5)),\n",
        "            num_classes=80,\n",
        "        ),\n",
        "        mask_in_features=[\"p2\", \"p3\", \"p4\", \"p5\"],\n",
        "        mask_pooler=ROIPooler(14, (1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32), 0, \"ROIAlignV2\"),\n",
        "        mask_head=MaskRCNNConvUpsampleHead(\n",
        "            ShapeSpec(channels=256, width=14, height=14),\n",
        "            num_classes=80,\n",
        "            conv_dims=[256, 256, 256, 256, 256],\n",
        "        ),\n",
        "    ),\n",
        "    pixel_mean=[103.530, 116.280, 123.675],\n",
        "    pixel_std=[1.0, 1.0, 1.0],\n",
        "    input_format=\"BGR\",\n",
        ")"
      ],
      "metadata": {
        "id": "p-HjrwcDeolb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|"
      ],
      "metadata": {
        "id": "Hn9RKx8hNIgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detectron2 Instructions"
      ],
      "metadata": {
        "id": "UuZKJvMR4NH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec"
      ],
      "metadata": {
        "id": "y69I7wvw4Zcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ToyBackbone(Backbone):\n",
        "#   def __init__(self, cfg, input_shape):\n",
        "#     super().__init__()\n",
        "#     # create your own backbone\n",
        "#     self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=16, padding=3)\n",
        "\n",
        "#   def forward(self, image):\n",
        "#     return {\"conv1\": self.conv1(image)}   # dictionary\n",
        "\n",
        "#   def output_shape(self):\n",
        "#     return {\"conv1\": ShapeSpec(channels=64, stride=16)}   # dictionary"
      ],
      "metadata": {
        "id": "p-2T8mLP4QbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet Backbone Implementation\n",
        "Adaped from PyTorch Source Code"
      ],
      "metadata": {
        "id": "dNKfd1IO5GYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec\n",
        "# from detectron2.layers import FrozenBatchNorm2d\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from collections import OrderedDict\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch import Tensor\n",
        "from torch.jit.annotations import List\n",
        "\n",
        "\n",
        "__all__ = ['DenseNetBackbone', 'densenet121', 'densenet161',\n",
        "           'densenet169', 'densenet201', 'build_densenet_backbone']\n",
        "\n",
        "model_urls = {\n",
        "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
        "}\n"
      ],
      "metadata": {
        "id": "ajEh89wr5Mef"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _DenseLayer(nn.Module):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)),\n",
        "        self.drop_rate = float(drop_rate)\n",
        "        self.memory_efficient = memory_efficient\n",
        "\n",
        "    def bn_function(self, inputs):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
        "        return bottleneck_output\n",
        "\n",
        "    # todo: rewrite when torchscript supports any\n",
        "    def any_requires_grad(self, input):\n",
        "        # type: (List[Tensor]) -> bool\n",
        "        for tensor in input:\n",
        "            if tensor.requires_grad:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    @torch.jit.unused  # noqa: T484\n",
        "    def call_checkpoint_bottleneck(self, input):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        def closure(*inputs):\n",
        "            return self.bn_function(inputs)\n",
        "\n",
        "        return cp.checkpoint(closure, *input)\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input):\n",
        "        # type: (List[Tensor]) -> (Tensor)\n",
        "        pass\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input):\n",
        "        # type: (Tensor) -> (Tensor)\n",
        "        pass\n",
        "\n",
        "    # torchscript does not yet support *args, so we overload method\n",
        "    # allowing it to take either a List[Tensor] or single Tensor\n",
        "    def forward(self, input):  # noqa: F811\n",
        "        if isinstance(input, Tensor):\n",
        "            prev_features = [input]\n",
        "        else:\n",
        "            prev_features = input\n",
        "\n",
        "        if self.memory_efficient and self.any_requires_grad(prev_features):\n",
        "            if torch.jit.is_scripting():\n",
        "                raise Exception(\"Memory Efficient not supported in JIT\")\n",
        "\n",
        "            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n",
        "        else:\n",
        "            bottleneck_output = self.bn_function(prev_features)\n",
        "\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return new_features\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.ModuleDict):\n",
        "    _version = 2\n",
        "\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(\n",
        "                num_input_features + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                bn_size=bn_size,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient,\n",
        "            )\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "    def forward(self, init_features):\n",
        "        features = [init_features]\n",
        "        for name, layer in self.items():\n",
        "            new_features = layer(features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNetBackbone(Backbone):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, memory_efficient=False):\n",
        "                # added cfg\n",
        "                # removed num_classes=1000\n",
        "\n",
        "        super(DenseNetBackbone, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
        "                                padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                num_input_features=num_features,\n",
        "                bn_size=bn_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient\n",
        "            )\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        # self.classifier = nn.Linear(num_features, num_classes)   # don't need\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            # elif isinstance(m, nn.Linear):\n",
        "            #     nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    #     _freeze_backbone(self, cfg.MODEL.BACKBONE.FREEZE_AT)\n",
        "\n",
        "    # # See this function for resnets to see how they access parameters in submodules, etc\n",
        "    # def _freeze_backbone(self, freeze_at):\n",
        "    #     if freeze_at < 0:\n",
        "    #         return\n",
        "\n",
        "    #     # APPROACH 1\n",
        "    #     for name, m in self.named_modules():\n",
        "    #         if 'denseblock4' in name:\n",
        "    #             # NEED TO ITERATE THROUGH FIRST FEW LAYERS\n",
        "    #             # cnt = 0\n",
        "    #             # Something with -> for child in model.children() and child.parameters\n",
        "    #             for layer_index in range(freeze_at):\n",
        "    #                 for p in m.parameters():\n",
        "    #                     p.requires_grad = False\n",
        "    #                     FrozenBatchNorm2d.convert_frozen_batchnorm(self)   # arguments correct?\n",
        "\n",
        "    #             break   # only want to train parameters starting at least in denseblock4\n",
        "    #         else:\n",
        "    #             for p in m.parameters():\n",
        "    #                 p.requires_grad = False\n",
        "    #                 FrozenBatchNorm2d.convert_frozen_batchnorm(self)   # arguments correct?\n",
        "\n",
        "\n",
        "    #     # APPROACH 2\n",
        "    #     for m in self.modules():\n",
        "    #         if m.name == 'denseblock4':   # may not be able to access name like this\n",
        "    #             for layer_index in range(freeze_at):\n",
        "    #                 for p in m.parameters():\n",
        "    #                     p.requires_grad = False\n",
        "    #                     FrozenBatchNorm2d.convert_frozen_batchnorm(self)   # arguments correct?\n",
        "\n",
        "    #             break   # only want to train parameters starting at least in denseblock4\n",
        "    #         else:\n",
        "    #             for p in m.parameters():\n",
        "    #                 p.requires_grad = False\n",
        "    #                 FrozenBatchNorm2d.convert_frozen_batchnorm(self)   # arguments correct?\n",
        "\n",
        "        \n",
        "    def forward(self, x):   # x is the input image\n",
        "        features = self.features(x)\n",
        "        # Might want these two\n",
        "        # out = F.relu(features, inplace=True)\n",
        "        # out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        return {\"SoleStage\": features}\n",
        "        # out = torch.flatten(out, 1)\n",
        "        # out = self.classifier(out)\n",
        "        # return out\n",
        "\n",
        "    def output_shape(self):\n",
        "        # Change stride to 16?\n",
        "        return {\"SoleStage\": ShapeSpec(channels=cfg.MODEL.DENSENET.OUT_CHANNELS, stride=4)}\n",
        "\n",
        "\n",
        "def _load_state_dict(model, model_url, progress):\n",
        "    # '.'s are no longer allowed in module names, but previous _DenseLayer\n",
        "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "    # They are also in the checkpoints in model_urls. This pattern is used\n",
        "    # to find such keys.\n",
        "    pattern = re.compile(\n",
        "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "\n",
        "    state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
        "    # Delete these two since classifier is removed from the network\n",
        "    del state_dict[\"classifier.weight\"]\n",
        "    del state_dict[\"classifier.bias\"]\n",
        "    for key in list(state_dict.keys()):\n",
        "        res = pattern.match(key)\n",
        "        if res:\n",
        "            new_key = res.group(1) + res.group(2)\n",
        "            state_dict[new_key] = state_dict[key]\n",
        "            del state_dict[key]\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "def _densenet(cfg, arch, growth_rate, block_config, num_init_features, pretrained, progress,\n",
        "              **kwargs):\n",
        "    model = DenseNetBackbone(cfg, growth_rate, block_config, num_init_features, **kwargs)\n",
        "    if pretrained:\n",
        "        _load_state_dict(model, model_urls[arch], progress)\n",
        "    return model\n",
        "\n",
        "def densenet121(cfg, pretrained=True, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet(cfg, 'densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet161(cfg, pretrained=True, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet(cfg, 'densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet169(cfg, pretrained=True, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet(cfg, 'densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet201(cfg, pretrained=True, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet(cfg, 'densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n",
        "                     **kwargs)\n"
      ],
      "metadata": {
        "id": "x6A5OGWS5N5E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Register function for creating backbones (VoVNet source code approach)"
      ],
      "metadata": {
        "id": "WBbjFX54q3FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@BACKBONE_REGISTRY.register()\n",
        "def build_densenet_backbone(cfg, input_shape: ShapeSpec):\n",
        "    \"\"\"\n",
        "    Create a DenseNetBackbone instance from config.\n",
        "    Returns:\n",
        "        DenseNetBackbone: a :class:`DenseNetBackbone` instance.\n",
        "    \"\"\"\n",
        "    conv_body = cfg.MODEL.DENSENET.CONV_BODY\n",
        "    pretrained = cfg.MODEL.DENSENET.PRETRAINED\n",
        "    if conv_body == \"densenet121\":\n",
        "      return densenet121(cfg, pretrained=pretrained)\n",
        "    elif conv_body == \"densenet161\":\n",
        "      return densenet161(cfg, pretrained=pretrained)\n",
        "    elif conv_body == \"densenet169\":\n",
        "      return densenet169(cfg, pretrained=pretrained)\n",
        "    elif conv_body == \"densenet201\":\n",
        "      return densenet201(cfg, pretrained=pretrained)\n",
        "    else:\n",
        "      return densenet121(cfg, pretrained=pretrained)"
      ],
      "metadata": {
        "id": "yQ1otqAEq69f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|\n",
        "\n",
        "|"
      ],
      "metadata": {
        "id": "nmDUomnBw6lE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a custom model"
      ],
      "metadata": {
        "id": "WQBiA7SKkzUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import GeneralizedRCNN, FPN, StandardROIHeads\n",
        "from detectron2.modeling.matcher import Matcher\n",
        "from detectron2.modeling.proposal_generator.rpn import RPN, StandardRPNHead\n",
        "from detectron2.modeling.backbone.fpn import LastLevelMaxPool\n",
        "from detectron2.modeling.anchor_generator import DefaultAnchorGenerator\n",
        "from detectron2.modeling.poolers import ROIPooler\n",
        "from detectron2.modeling.box_regression import Box2BoxTransform\n",
        "from detectron2.modeling.roi_heads.box_head import FastRCNNConvFCHead\n",
        "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers"
      ],
      "metadata": {
        "id": "aHQUmwwJtFsV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.config import get_cfg\n",
        "\n",
        "# initialize config object\n",
        "cfg = get_cfg()"
      ],
      "metadata": {
        "id": "PBB2pdrKijOY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add_densenet_config function\n",
        "from detectron2.config import CfgNode as CN\n",
        "\n",
        "model_channels = {\n",
        "    'densenet121': 1024,\n",
        "    'densenet161': 2208,\n",
        "    'densenet169': 1664,\n",
        "    'densenet201': 1920,\n",
        "}\n",
        "\n",
        "_C = cfg\n",
        "\n",
        "_C.MODEL.DENSENET = CN()\n",
        "\n",
        "_C.MODEL.DENSENET.CONV_BODY = \"densenet201\"\n",
        "_C.MODEL.DENSENET.OUT_FEATURES = [\"SoleStage\"]\n",
        "\n",
        "_C.MODEL.DENSENET.PRETRAINED = True\n",
        "\n",
        "_C.MODEL.DENSENET.OUT_CHANNELS = model_channels[\"densenet201\"]\n",
        "\n",
        "_C.MODEL.BACKBONE.NAME = \"build_densenet_backbone\"\n",
        "\n",
        "# Other settings in config file\n",
        "\n",
        "# cfg.MODEL.BACKBONE.FREEZE_AT = 4\n"
      ],
      "metadata": {
        "id": "FkOoKas4jQMd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a model with explicit arguments"
      ],
      "metadata": {
        "id": "PvKKA7hixXBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GeneralizedRCNN(\n",
        "    # backbone = densenet121(cfg),\n",
        "    backbone = build_densenet_backbone(cfg),\n",
        "    proposal_generator=RPN(\n",
        "        in_features=[\"SoleStage\"],\n",
        "        head=StandardRPNHead(in_channels=cfg.MODEL.DENSENET.OUT_CHANNELS, num_anchors=15),\n",
        "        anchor_generator=DefaultAnchorGenerator(\n",
        "            sizes=[32, 64, 128, 256, 512],\n",
        "            aspect_ratios=[0.5, 1.0, 2.0],\n",
        "            strides=[4],   # change to 16?\n",
        "            offset=0.0,   # recommended 0.5\n",
        "        ),\n",
        "        anchor_matcher=Matcher([0.3, 0.7], [0, -1, 1], allow_low_quality_matches=True),\n",
        "        box2box_transform=Box2BoxTransform([1.0, 1.0, 1.0, 1.0]),   # what values to use?\n",
        "        batch_size_per_image=256,   # training\n",
        "        positive_fraction=0.5,   # 128:128 ratio\n",
        "        pre_nms_topk=(2000, 1000),\n",
        "        post_nms_topk=(1000, 1000),\n",
        "        nms_thresh=0.7,\n",
        "    ),\n",
        "    roi_heads=StandardROIHeads(\n",
        "        num_classes=10,\n",
        "        batch_size_per_image=512,   # training\n",
        "        positive_fraction=0.25,   # 128:384 ratio (training)   # use 0.5?\n",
        "        proposal_matcher=Matcher([0.5], [0, 1], allow_low_quality_matches=False),\n",
        "        box_in_features=[\"SoleStage\"],\n",
        "        # box_pooler=ROIPooler(7, (1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32), 0, \"ROIAlignV2\"),\n",
        "        box_pooler=ROIPooler(7, (1.0 / 4,), 2, \"ROIAlignV2\"),   # match the stride above; 2 is the sampling ratio of ROIAlign (previously 0)\n",
        "        box_head=FastRCNNConvFCHead(\n",
        "            ShapeSpec(channels=cfg.MODEL.DENSENET.OUT_CHANNELS, height=7, width=7), \n",
        "            conv_dims=[], fc_dims=[cfg.MODEL.DENSENET.OUT_CHANNELS, cfg.MODEL.DENSENET.OUT_CHANNELS]\n",
        "        ),\n",
        "        box_predictor=FastRCNNOutputLayers(\n",
        "            ShapeSpec(channels=cfg.MODEL.DENSENET.OUT_CHANNELS),\n",
        "            test_score_thresh=0.05,\n",
        "            box2box_transform=Box2BoxTransform((10, 10, 5, 5)),   # what values to use?\n",
        "            num_classes=10,\n",
        "            test_nms_thresh = 0.7   # default is 0.5\n",
        "        ),\n",
        "    ),\n",
        "    pixel_mean=[103.530, 116.280, 123.675],   # to normalize; equal to ImageNet pixel mean\n",
        "    pixel_std=[1.0, 1.0, 1.0],   # to normalize; ImageNet std is [57.375, 57.120, 58.395]\n",
        "    input_format=\"BGR\",\n",
        ")"
      ],
      "metadata": {
        "id": "w9zuckeCE_-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create model from config and explicit arguments.\n",
        "Currently not correct.\n"
      ],
      "metadata": {
        "id": "MyK-6_rPkgue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import build_model\n",
        "\n",
        "# cgf = get_cfg()\n",
        "# cfg.merge_from_file(\"my_cfg.yaml\")   # read a config\n",
        "# cfg.merge_from_list()\n",
        "# model = build_model(cfg)\n",
        "\n",
        "# cfg for some settings, explicit arguments for more complicated arguments\n",
        "model = GeneralizedRCNN(\n",
        "    cfg,\n",
        "    proposal_generator=RPN(\n",
        "        in_features=[\"SoleStage\"],\n",
        "        head=StandardRPNHead(in_channels=cfg.MODEL.DENSENET.OUT_CHANNELS, num_anchors=15),\n",
        "        anchor_generator=DefaultAnchorGenerator(\n",
        "            sizes=[32, 64, 128, 256, 512],\n",
        "            aspect_ratios=[0.5, 1.0, 2.0],\n",
        "            strides=[4],   # change to 16?\n",
        "            offset=0.0,   # recommended 0.5\n",
        "        ),\n",
        "        anchor_matcher=Matcher([0.3, 0.7], [0, -1, 1], allow_low_quality_matches=True),\n",
        "        box2box_transform=Box2BoxTransform([1.0, 1.0, 1.0, 1.0]),   # what values to use?\n",
        "        batch_size_per_image=256,   # training\n",
        "        positive_fraction=0.5,   # 128:128 ratio\n",
        "        pre_nms_topk=(2000, 1000),\n",
        "        post_nms_topk=(1000, 1000),\n",
        "        nms_thresh=0.7,\n",
        "    ),\n",
        "    roi_heads=StandardROIHeads(\n",
        "        num_classes=10,\n",
        "        batch_size_per_image=512,   # training\n",
        "        positive_fraction=0.25,   # 128:384 ratio (training)   # use 0.5?\n",
        "        proposal_matcher=Matcher([0.5], [0, 1], allow_low_quality_matches=False),\n",
        "        box_in_features=[\"SoleStage\"],\n",
        "        # box_pooler=ROIPooler(7, (1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32), 0, \"ROIAlignV2\"),\n",
        "        box_pooler=ROIPooler(7, (1.0 / 4,), 0, \"ROIAlignV2\"),   # match the stride above; 2 is the sampling ratio of ROIAlign (previously 0)\n",
        "        box_head=FastRCNNConvFCHead(\n",
        "            ShapeSpec(channels=cfg.MODEL.DENSENET.OUT_CHANNELS, height=7, width=7), \n",
        "            conv_dims=[], fc_dims=[cfg.MODEL.DENSENET.OUT_CHANNELS, cfg.MODEL.DENSENET.OUT_CHANNELS]\n",
        "        ),\n",
        "        box_predictor=FastRCNNOutputLayers(\n",
        "            ShapeSpec(channels=cfg.MODEL.DENSENET.OUT_CHANNELS),\n",
        "            test_score_thresh=0.05,\n",
        "            box2box_transform=Box2BoxTransform((10, 10, 5, 5)),   # what values to use?\n",
        "            num_classes=10,\n",
        "            test_nms_thresh = 0.7   # default is 0.5\n",
        "        ),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "oakmZHn_zDav"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a model from cfg file."
      ],
      "metadata": {
        "id": "libMzp5ITD1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.config import CfgNode as CN\n",
        "\n",
        "model_channels = {\n",
        "    'densenet121': 1024,\n",
        "    'densenet161': 2208,\n",
        "    'densenet169': 1664,\n",
        "    'densenet201': 1920,\n",
        "}\n",
        "\n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.MODEL.META_ARCHITECTURE = \"GeneralizedRCNN\"\n",
        "\n",
        "cfg.MODEL.PIXEL_MEAN = [103.530, 116.280, 123.675]\n",
        "cfg.MODEL.PIXEL_STD = [1.0, 1.0, 1.0]\n",
        "cfg.INPUT.FORMAT = \"BGR\"\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = 640\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 640\n",
        "cfg.INPUT.MIN_SIZE_TEST = 640\n",
        "cfg.INPUT.MAX_SIZE_TEST = 640\n",
        "\n",
        "# List of the dataset names for training. Must be registered in DatasetCatalog\n",
        "# Samples from these datasets will be merged and used as one dataset.\n",
        "cfg.DATASETS.TRAIN = (\"birds_species_train\",)\n",
        "# # Number of top scoring precomputed proposals to keep for training\n",
        "# _C.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TRAIN = 2000\n",
        "# List of the dataset names for testing. Must be registered in DatasetCatalog\n",
        "cfg.DATASETS.TEST = (\"birds_species_val\",)\n",
        "# # Number of top scoring precomputed proposals to keep for test\n",
        "# _C.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TEST = 1000\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "\n",
        "cfg.MODEL.DENSENET = CN()\n",
        "cfg.MODEL.DENSENET.CONV_BODY = \"densenet121\"\n",
        "cfg.MODEL.DENSENET.PRETRAINED = True\n",
        "cfg.MODEL.DENSENET.OUT_FEATURES = [\"SoleStage\"]\n",
        "cfg.MODEL.DENSENET.OUT_CHANNELS = model_channels[\"densenet121\"]\n",
        "\n",
        "cfg.MODEL.BACKBONE.NAME = \"build_densenet_backbone\"\n",
        "cfg.MODEL.BACKBONE.FREEZE_AT = 4\n",
        "\n",
        "# cfg.MODEL.PROPOSAL_GENERATOR.NAME = \"RPN\"   # Don't think it's needed\n",
        "\n",
        "cfg.MODEL.ANCHOR_GENERATOR.NAME = \"DefaultAnchorGenerator\"\n",
        "# Anchor sizes (i.e. sqrt of area) in absolute pixels w.r.t. the network input.\n",
        "# Format: list[list[float]]. SIZES[i] specifies the list of sizes to use for\n",
        "# IN_FEATURES[i]; len(SIZES) must be equal to len(IN_FEATURES) or 1.\n",
        "# When len(SIZES) == 1, SIZES[0] is used for all IN_FEATURES.\n",
        "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[32, 64, 128, 256, 512]]\n",
        "# Anchor aspect ratios. For each area given in `SIZES`, anchors with different aspect\n",
        "# ratios are generated by an anchor generator.\n",
        "# Format: list[list[float]]. ASPECT_RATIOS[i] specifies the list of aspect ratios (H/W)\n",
        "# to use for IN_FEATURES[i]; len(ASPECT_RATIOS) == len(IN_FEATURES) must be true,\n",
        "# or len(ASPECT_RATIOS) == 1 is true and aspect ratio list ASPECT_RATIOS[0] is used\n",
        "# for all IN_FEATURES.\n",
        "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0, 2.0]]\n",
        "# Relative offset between the center of the first anchor and the top-left corner of the image\n",
        "# Value has to be in [0, 1). Recommend to use 0.5, which means half stride.\n",
        "# The value is not expected to affect model accuracy.\n",
        "cfg.MODEL.ANCHOR_GENERATOR.OFFSET = 0.0\n",
        "\n",
        "cfg.MODEL.RPN.HEAD_NAME = \"StandardRPNHead\"  # used by RPN_HEAD_REGISTRY\n",
        "# Names of the input feature maps to be used by RPN\n",
        "cfg.MODEL.RPN.IN_FEATURES = [\"SoleStage\"]\n",
        "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.3, 0.7]\n",
        "cfg.MODEL.RPN.IOU_LABELS = [0, -1, 1]\n",
        "# Number of regions per image used to train RPN\n",
        "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 256\n",
        "# Target fraction of foreground (positive) examples per RPN minibatch\n",
        "cfg.MODEL.RPN.POSITIVE_FRACTION = 0.5\n",
        "# Options are: \"smooth_l1\", \"giou\", \"diou\", \"ciou\"\n",
        "# _C.MODEL.RPN.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
        "# _C.MODEL.RPN.BBOX_REG_LOSS_WEIGHT = 1.0\n",
        "# # Weights on (dx, dy, dw, dh) for normalizing RPN anchor regression targets\n",
        "# _C.MODEL.RPN.BBOX_REG_WEIGHTS = (1.0, 1.0, 1.0, 1.0)   # Box2BoxTransform arguments?\n",
        "# # The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.\n",
        "# _C.MODEL.RPN.SMOOTH_L1_BETA = 0.0\n",
        "# _C.MODEL.RPN.LOSS_WEIGHT = 1.0\n",
        "# Number of top scoring RPN proposals to keep before applying NMS\n",
        "# When FPN is used, this is *per FPN level* (not total)\n",
        "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 2000   # 12000\n",
        "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 1000   # 6000\n",
        "# Number of top scoring RPN proposals to keep after applying NMS\n",
        "# When FPN is used, this limit is applied per level and then again to the union\n",
        "# of proposals from all levels\n",
        "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 1000   # 2000\n",
        "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 1000\n",
        "# NMS threshold used on RPN proposals\n",
        "cfg.MODEL.RPN.NMS_THRESH = 0.7\n",
        "# Set this to -1 to use the same number of output channels as input channels.\n",
        "# _C.MODEL.RPN.CONV_DIMS = [-1]\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.NAME = \"StandardROIHeads\"\n",
        "# Number of foreground classes\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10   # overwritten\n",
        "cfg.MODEL.ROI_HEADS.IN_FEATURES = [\"SoleStage\"]\n",
        "# IOU overlap ratios [IOU_THRESHOLD]\n",
        "# Overlap threshold for an RoI to be considered background (if < IOU_THRESHOLD)\n",
        "# Overlap threshold for an RoI to be considered foreground (if >= IOU_THRESHOLD)\n",
        "cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5]\n",
        "cfg.MODEL.ROI_HEADS.IOU_LABELS = [0, 1]\n",
        "# RoI minibatch size *per image* (number of regions of interest [ROIs]) during training\n",
        "# Total number of RoIs per training minibatch =\n",
        "#   ROI_HEADS.BATCH_SIZE_PER_IMAGE * SOLVER.IMS_PER_BATCH\n",
        "# E.g., a common configuration is: 512 * 16 = 8192\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "# Target fraction of RoI minibatch that is labeled foreground (i.e. class > 0)\n",
        "cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.25\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.7   # 0.5\n",
        "\n",
        "cfg.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
        "# # Options are: \"smooth_l1\", \"giou\", \"diou\", \"ciou\"\n",
        "# _C.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
        "# # The final scaling coefficient on the box regression loss, used to balance the magnitude of its\n",
        "# # gradients with other losses in the model. See also `MODEL.ROI_KEYPOINT_HEAD.LOSS_WEIGHT`.\n",
        "# _C.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 1.0\n",
        "# Default weights on (dx, dy, dw, dh) for normalizing bbox regression targets\n",
        "# These are empirically chosen to approximately lead to unit variance targets\n",
        "# _C.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS = (10.0, 10.0, 5.0, 5.0)\n",
        "# # The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.\n",
        "# _C.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA = 0.0\n",
        "cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 7\n",
        "cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO = 2   # 0\n",
        "# Type of pooling operation applied to the incoming feature map for each RoI\n",
        "cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE = \"ROIAlignV2\"\n",
        "\n",
        "cfg.MODEL.ROI_BOX_HEAD.NUM_FC = 2\n",
        "# Hidden layer dimension for FC layers in the RoI box head\n",
        "cfg.MODEL.ROI_BOX_HEAD.FC_DIM = 1024   # Set to cfg.MODEL.DENSENET.OUT_CHANNELS\n",
        "# _C.MODEL.ROI_BOX_HEAD.NUM_CONV = 0\n",
        "# Channel dimension for Conv layers in the RoI box head\n",
        "# _C.MODEL.ROI_BOX_HEAD.CONV_DIM = 256\n",
        "\n"
      ],
      "metadata": {
        "id": "iELplkHrzQCu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import build_model\n",
        "\n",
        "model = build_model(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "aeca394c98ff46888311adc415e97964",
            "d5681ce5ac83459ba0bdbe7a4d69b293",
            "73b670cf0b02477086aaf341f15ac7f0",
            "aa5290c927a54c5aba76609dbe96eb4c",
            "91e683eba41749108d1d0854b65741bf",
            "0f176a7b37254543b8873c27fcd2dc08",
            "64536a69e1ab4b45be26cfde560dea6d",
            "fbf8adcf35ba4b8ea3227de555f39f0f",
            "b7e3c107a81b4f94ab18a34d55b16507",
            "3df9b9e9c3954a509f2f057d5ca23409",
            "6d25826b89914c8890b51e72c60aae47"
          ]
        },
        "id": "dp6G_4Dc97YG",
        "outputId": "b9e90ab0-e1ec-49f9-8ff4-246bbb798510"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeca394c98ff46888311adc415e97964"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ],
      "metadata": {
        "id": "MvCg4l706xiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/data/tiled/DJI_20210520121102_0600_0_12.JPEG   # has none\n",
        "# /content/data/tiled/DJI_20210520121102_0600_8_12.JPEG\n",
        "# /content/data/tiled/DJI_20210520121104_0601_2_4.JPEG\n",
        "# /content/data/tiled/DJI_20210520121105_0602_3_13.JPEG\n",
        "# /content/data/tiled/DJI_20210520121107_0603_8_13.JPEG\n",
        "# /content/data/tiled/DJI_20210520121109_0604_1_4.JPEG\n",
        "# /content/data/tiled/DJI_20210520121111_0605_0_0.JPEG\n",
        "\n",
        "im1 = cv2.imread(\"/content/data/split/train/DJI_20210520121109_0604_1_4.JPEG\")\n",
        "# im1 = cv2.imread(\"/content/data/tiled/DJI_20210520121109_0604_1_4.JPEG\")\n",
        "im1 = torch.as_tensor(im1.astype(\"float32\").transpose(2, 0, 1))\n",
        "# im1 = torch.as_tensor(im1.astype(\"float32\"))\n",
        "\n",
        "im2 = cv2.imread(\"/content/data/split/train/DJI_20210520121111_0605_0_0.JPEG\")\n",
        "# im2 = cv2.imread(\"/content/data/tiled/DJI_20210520121111_0605_0_0.JPEG\")\n",
        "im2 = torch.as_tensor(im2.astype(\"float32\").transpose(2, 0, 1))\n",
        "# im2 = torch.as_tensor(im2.astype(\"float32\"))\n",
        "\n",
        "im3 = cv2.imread(\"/content/data/split/train/DJI_20210520121107_0603_8_13.JPEG\")\n",
        "# im3 = cv2.imread(\"/content/data/tiled/DJI_20210520121107_0603_8_13.JPEG\")\n",
        "im3 = torch.as_tensor(im3.astype(\"float32\").transpose(2, 0, 1))\n",
        "# im3 = torch.as_tensor(im3.astype(\"float32\"))\n",
        "\n",
        "im4 = cv2.imread(\"/content/data/split/test/DJI_20210520121105_0602_3_13.JPEG\")\n",
        "# im4 = cv2.imread(\"/content/data/tiled/DJI_20210520121105_0602_3_13.JPEG\")\n",
        "im4 = torch.as_tensor(im4.astype(\"float32\").transpose(2, 0, 1))\n",
        "# im4 = torch.as_tensor(im4.astype(\"float32\"))\n",
        "\n",
        "# cv2_imshow(im)\n",
        "# type(image)\n",
        "\n",
        "images = [im1, im2, im3, im4]"
      ],
      "metadata": {
        "id": "qYldFEd2BAn7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "for im in images:\n",
        "  height, width = im.shape[1:]    # get 0 to 1\n",
        "  if model.input_format == \"RGB\":\n",
        "      # convert to RGB image to BGR (cv2.imread() reads in image as BGR)\n",
        "      # im = im[:, :, ::-1]\n",
        "      im = im[::-1, :, :]   # Think it should be this because channels in now in the 0th dimension\n",
        "\n",
        "  input = {\"image\": im, \"height\": height, \"width\": width}\n",
        "  # inputs = {\"image\": im}\n",
        "  inputs.append(input)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  outputs = model(inputs)   # must be a list of dictionaries"
      ],
      "metadata": {
        "id": "CL-H2_u312Td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a91d327-81ce-4853-d2ed-bd8e3bd22d9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(inputs)):\n",
        "  print(outputs[i][\"instances\"].pred_classes)\n",
        "  # print(outputs[i][\"instances\"].pred_boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5E7MySTvplt",
        "outputId": "b74eb0a0-3625-4e70-e8eb-feb07f32ea6e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 8, 8, 8, 5, 5, 5, 5, 2, 5, 5, 8, 8, 8, 8, 8, 5, 5, 8, 8, 8, 8, 5, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8, 5, 5, 8, 5, 8, 8, 5, 8, 3, 8, 8, 8, 8, 8, 8, 8,\n",
            "        5, 8, 2, 8, 8, 8, 8, 8, 8, 5, 8, 8, 5, 8, 5, 8, 8, 8, 8, 8, 5, 8, 5, 5,\n",
            "        8, 8, 5, 5, 5, 8, 2, 8, 8, 8, 8, 8, 5, 5, 5, 5, 8, 5, 8, 8, 8, 8, 2, 8,\n",
            "        5, 8, 8, 5], device='cuda:0')\n",
            "tensor([8, 8, 3, 8, 3, 8, 8, 8, 8, 8, 5, 8, 9, 8, 8, 8, 8, 8, 8, 9, 5, 9, 3, 8,\n",
            "        8, 8, 8, 3, 8, 3, 9, 8, 8, 6, 3, 9, 3, 8, 8, 3, 8, 8, 8, 2, 8, 8, 3, 6,\n",
            "        3, 8, 8, 3, 6, 8, 3, 3, 2, 8, 3, 8, 9, 9, 8, 8, 8, 8, 9, 8, 3, 8, 3, 8,\n",
            "        8, 5, 8, 6, 3, 3, 3, 3, 3, 8, 8, 2, 8, 2, 3, 3, 5, 9, 3, 8, 3, 3, 3, 8,\n",
            "        8, 3, 2, 8], device='cuda:0')\n",
            "tensor([8, 5, 5, 5, 8, 8, 8, 8, 5, 5, 8, 5, 5, 8, 8, 5, 5, 8, 8, 8, 8, 8, 5, 8,\n",
            "        8, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 5, 8, 5, 5, 5, 8, 8, 5,\n",
            "        8, 8, 5, 5, 8, 8, 5, 5, 5, 8, 5, 5, 8, 5, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 5, 8, 5, 5, 8, 3, 8, 8, 5, 8, 5, 8, 8, 8, 5, 8, 8, 8, 5, 8, 8,\n",
            "        8, 8, 8, 8], device='cuda:0')\n",
            "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 8,\n",
            "        8, 5, 8, 8, 5, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8, 5, 8, 5, 8, 8, 5,\n",
            "        8, 5, 2, 8, 2, 8, 2, 2, 8, 2, 2, 8, 8, 8, 8, 5, 8, 5, 2, 8, 8, 8, 2, 2,\n",
            "        2, 8, 8, 8, 5, 5, 8, 8, 5, 5, 2, 8, 8, 8, 8, 8, 2, 2, 8, 8, 8, 2, 8, 5,\n",
            "        8, 5, 2, 8], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "5YAh3iMls57C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.engine import DefaultPredictor\n",
        "# from Audubon_F21.utils.trainer import Trainer\n",
        "from detectron2.engine import DefaultTrainer"
      ],
      "metadata": {
        "id": "99Gg4S0EvJm5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup training logger \n",
        "setup_logger()\n",
        "\n",
        "BIRD_SPECIES = [\"Brown Pelican\", \"Laughing Gull\", \"Mixed Tern\",\n",
        "                \"Great Blue Heron\",\"Great Egret/White Morph\"]   # not really used\n",
        "SPECIES_MAP = {0: 'Brown Pelican', 1: 'Laughing Gull', 2: 'Mixed Tern', 3: 'Great Blue Heron',\n",
        "               4: 'Great Egret/White Morph', 5: 'Other/Unknown'}\n",
        "\n",
        "model_name = \"densenet121\"\n",
        "\n",
        "# add datasets used for training and validation \n",
        "cfg.DATASETS.TRAIN = (\"birds_species_train\",)\n",
        "cfg.DATASETS.TEST = (\"birds_species_val\",)   # val vs test?\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1   # what's a good number for 1 GPU?\n",
        "cfg.SOLVER.BASE_LR = 1e-3   # pick a good learning rate, 0.00025 is what tutorial uses\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "cfg.SOLVER.WARMUP_ITERS = 1\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES)\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = [500,]   # [] to not decay the learning rate\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1\n",
        "\n",
        "cfg.OUTPUT_DIR = f\"./output/multibirds_{model_name}\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# train on bird species\n",
        "trainer = DefaultTrainer(cfg)   # DefaultTrainer(cfg) if not using a custom trainer\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa4nr7Bus3Fd",
        "outputId": "befc6fb9-ec3d-460c-ba45-45a0cac1ecd8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/25 17:18:10 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): DenseNetBackbone(\n",
            "    (features): Sequential(\n",
            "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU(inplace=True)\n",
            "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (denseblock1): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition1): _Transition(\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock2): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition2): _Transition(\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock3): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer13): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer14): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer15): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer16): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer17): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer18): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer19): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer20): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer21): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer22): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer23): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer24): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition3): _Transition(\n",
            "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock4): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer13): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer14): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer15): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer16): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=50176, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[03/25 17:18:13 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 365 images left.\n",
            "\u001b[32m[03/25 17:18:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[03/25 17:18:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[03/25 17:18:14 d2.data.common]: \u001b[0mSerializing 365 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/25 17:18:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "\u001b[32m[03/25 17:18:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[03/25 17:18:21 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 19  total_loss: 3.342  loss_cls: 1.305  loss_box_reg: 0  loss_rpn_cls: 0.3722  loss_rpn_loc: 1.295  time: 0.3313  data_time: 0.0170  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:18:27 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 39  total_loss: 5.377  loss_cls: 1.619  loss_box_reg: 0  loss_rpn_cls: 0.3555  loss_rpn_loc: 3.641  time: 0.3308  data_time: 0.0045  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:18:34 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 59  total_loss: 3.453  loss_cls: 1.382  loss_box_reg: 0  loss_rpn_cls: 0.2923  loss_rpn_loc: 1.791  time: 0.3306  data_time: 0.0039  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:18:40 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 79  total_loss: 4.543  loss_cls: 1.126  loss_box_reg: 0  loss_rpn_cls: 0.3393  loss_rpn_loc: 3.124  time: 0.3302  data_time: 0.0038  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:18:47 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 99  total_loss: 2.897  loss_cls: 0.8611  loss_box_reg: 0  loss_rpn_cls: 0.446  loss_rpn_loc: 1.675  time: 0.3301  data_time: 0.0038  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:18:54 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 119  total_loss: 3.573  loss_cls: 0.6118  loss_box_reg: 0  loss_rpn_cls: 0.3554  loss_rpn_loc: 2.649  time: 0.3300  data_time: 0.0033  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:00 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 139  total_loss: 3.263  loss_cls: 0.428  loss_box_reg: 0  loss_rpn_cls: 0.3076  loss_rpn_loc: 2.605  time: 0.3299  data_time: 0.0036  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:07 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 159  total_loss: 2.97  loss_cls: 0.3223  loss_box_reg: 0  loss_rpn_cls: 0.2695  loss_rpn_loc: 2.417  time: 0.3300  data_time: 0.0043  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:13 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 179  total_loss: 2.938  loss_cls: 0.2235  loss_box_reg: 0  loss_rpn_cls: 0.2387  loss_rpn_loc: 2.482  time: 0.3301  data_time: 0.0034  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:20 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 199  total_loss: 2.582  loss_cls: 0.1566  loss_box_reg: 0  loss_rpn_cls: 0.2794  loss_rpn_loc: 2.148  time: 0.3303  data_time: 0.0039  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:27 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 219  total_loss: 2.309  loss_cls: 0.1132  loss_box_reg: 0  loss_rpn_cls: 0.2509  loss_rpn_loc: 1.953  time: 0.3304  data_time: 0.0041  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:33 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 239  total_loss: 2.081  loss_cls: 0.08908  loss_box_reg: 0  loss_rpn_cls: 0.3183  loss_rpn_loc: 1.742  time: 0.3305  data_time: 0.0038  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:40 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 259  total_loss: 2.424  loss_cls: 0.07173  loss_box_reg: 0  loss_rpn_cls: 0.3373  loss_rpn_loc: 2.02  time: 0.3306  data_time: 0.0041  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:47 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 279  total_loss: 2.69  loss_cls: 0.05885  loss_box_reg: 0  loss_rpn_cls: 0.3109  loss_rpn_loc: 2.377  time: 0.3305  data_time: 0.0039  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:19:54 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 299  total_loss: 1.491  loss_cls: 0.04946  loss_box_reg: 0  loss_rpn_cls: 0.5552  loss_rpn_loc: 0.8749  time: 0.3316  data_time: 0.0042  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:00 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 319  total_loss: 2.459  loss_cls: 0.04211  loss_box_reg: 0  loss_rpn_cls: 0.3648  loss_rpn_loc: 2.065  time: 0.3316  data_time: 0.0041  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:07 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 339  total_loss: 2.641  loss_cls: 0.03637  loss_box_reg: 0  loss_rpn_cls: 0.3502  loss_rpn_loc: 2.273  time: 0.3315  data_time: 0.0034  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:14 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 359  total_loss: 3.332  loss_cls: 0.03184  loss_box_reg: 0  loss_rpn_cls: 0.2825  loss_rpn_loc: 3.004  time: 0.3316  data_time: 0.0033  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:20 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 379  total_loss: 2.893  loss_cls: 0.0282  loss_box_reg: 0  loss_rpn_cls: 0.1896  loss_rpn_loc: 2.679  time: 0.3315  data_time: 0.0038  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:27 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 399  total_loss: 2.536  loss_cls: 0.02522  loss_box_reg: 0  loss_rpn_cls: 0.1536  loss_rpn_loc: 2.109  time: 0.3321  data_time: 0.0043  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:34 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 419  total_loss: 2.121  loss_cls: 0.02275  loss_box_reg: 0  loss_rpn_cls: 0.1747  loss_rpn_loc: 1.933  time: 0.3321  data_time: 0.0034  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:40 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 439  total_loss: 1.451  loss_cls: 0.02067  loss_box_reg: 0  loss_rpn_cls: 0.3288  loss_rpn_loc: 1.054  time: 0.3320  data_time: 0.0040  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:47 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 459  total_loss: 3.164  loss_cls: 0.01896  loss_box_reg: 0  loss_rpn_cls: 0.3488  loss_rpn_loc: 2.797  time: 0.3319  data_time: 0.0041  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:20:54 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 479  total_loss: 2.643  loss_cls: 0.01746  loss_box_reg: 0  loss_rpn_cls: 0.2799  loss_rpn_loc: 2.354  time: 0.3319  data_time: 0.0035  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:02 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 499  total_loss: 2.655  loss_cls: 0.01613  loss_box_reg: 0  loss_rpn_cls: 0.2275  loss_rpn_loc: 2.416  time: 0.3319  data_time: 0.0037  lr: 0.001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:09 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 519  total_loss: 2.037  loss_cls: 0.01545  loss_box_reg: 0  loss_rpn_cls: 0.2036  loss_rpn_loc: 1.819  time: 0.3318  data_time: 0.0035  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:15 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 539  total_loss: 2.519  loss_cls: 0.01534  loss_box_reg: 0  loss_rpn_cls: 0.2027  loss_rpn_loc: 2.301  time: 0.3317  data_time: 0.0037  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:22 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 559  total_loss: 1.88  loss_cls: 0.01523  loss_box_reg: 0  loss_rpn_cls: 0.2139  loss_rpn_loc: 1.664  time: 0.3316  data_time: 0.0036  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:29 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 579  total_loss: 2.416  loss_cls: 0.01512  loss_box_reg: 0  loss_rpn_cls: 0.226  loss_rpn_loc: 2.183  time: 0.3316  data_time: 0.0040  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:35 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 599  total_loss: 2.216  loss_cls: 0.01502  loss_box_reg: 0  loss_rpn_cls: 0.2243  loss_rpn_loc: 1.978  time: 0.3316  data_time: 0.0040  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:42 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 619  total_loss: 2.528  loss_cls: 0.01491  loss_box_reg: 0  loss_rpn_cls: 0.2273  loss_rpn_loc: 2.288  time: 0.3316  data_time: 0.0035  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:49 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 639  total_loss: 2.465  loss_cls: 0.01481  loss_box_reg: 0  loss_rpn_cls: 0.2283  loss_rpn_loc: 2.226  time: 0.3316  data_time: 0.0037  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:21:55 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 659  total_loss: 2.178  loss_cls: 0.0147  loss_box_reg: 0  loss_rpn_cls: 0.2285  loss_rpn_loc: 1.938  time: 0.3316  data_time: 0.0040  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:02 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 679  total_loss: 1.867  loss_cls: 0.0146  loss_box_reg: 0  loss_rpn_cls: 0.2295  loss_rpn_loc: 1.625  time: 0.3317  data_time: 0.0037  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:09 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 699  total_loss: 2.405  loss_cls: 0.0145  loss_box_reg: 0  loss_rpn_cls: 0.227  loss_rpn_loc: 2.167  time: 0.3318  data_time: 0.0034  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:15 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 719  total_loss: 1.389  loss_cls: 0.01441  loss_box_reg: 0  loss_rpn_cls: 0.2323  loss_rpn_loc: 1.144  time: 0.3317  data_time: 0.0040  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:22 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 739  total_loss: 1.164  loss_cls: 0.01431  loss_box_reg: 0  loss_rpn_cls: 0.6533  loss_rpn_loc: 0.4161  time: 0.3318  data_time: 0.0039  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:29 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 759  total_loss: 1.912  loss_cls: 0.01421  loss_box_reg: 0  loss_rpn_cls: 0.247  loss_rpn_loc: 1.657  time: 0.3318  data_time: 0.0036  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:35 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 779  total_loss: 2.452  loss_cls: 0.01412  loss_box_reg: 0  loss_rpn_cls: 0.2512  loss_rpn_loc: 2.19  time: 0.3318  data_time: 0.0037  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:42 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 799  total_loss: 1.905  loss_cls: 0.01402  loss_box_reg: 0  loss_rpn_cls: 0.2436  loss_rpn_loc: 1.649  time: 0.3318  data_time: 0.0034  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:49 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 819  total_loss: 2.149  loss_cls: 0.01393  loss_box_reg: 0  loss_rpn_cls: 0.253  loss_rpn_loc: 1.89  time: 0.3318  data_time: 0.0033  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:22:55 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 839  total_loss: 2.36  loss_cls: 0.01384  loss_box_reg: 0  loss_rpn_cls: 0.2536  loss_rpn_loc: 2.095  time: 0.3319  data_time: 0.0038  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:02 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 859  total_loss: 2.052  loss_cls: 0.01374  loss_box_reg: 0  loss_rpn_cls: 0.2537  loss_rpn_loc: 1.763  time: 0.3319  data_time: 0.0040  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:09 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 879  total_loss: 2.234  loss_cls: 0.01365  loss_box_reg: 0  loss_rpn_cls: 0.2595  loss_rpn_loc: 1.962  time: 0.3320  data_time: 0.0038  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:15 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 899  total_loss: 2.268  loss_cls: 0.01356  loss_box_reg: 0  loss_rpn_cls: 0.26  loss_rpn_loc: 2  time: 0.3320  data_time: 0.0037  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:22 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 919  total_loss: 1.633  loss_cls: 0.01348  loss_box_reg: 0  loss_rpn_cls: 0.4339  loss_rpn_loc: 1.036  time: 0.3321  data_time: 0.0036  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:29 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 939  total_loss: 2.286  loss_cls: 0.01339  loss_box_reg: 0  loss_rpn_cls: 0.2674  loss_rpn_loc: 2.006  time: 0.3322  data_time: 0.0041  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:36 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 959  total_loss: 2.58  loss_cls: 0.0133  loss_box_reg: 0  loss_rpn_cls: 0.2582  loss_rpn_loc: 2.307  time: 0.3322  data_time: 0.0034  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:42 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 979  total_loss: 1.789  loss_cls: 0.01322  loss_box_reg: 0  loss_rpn_cls: 0.2574  loss_rpn_loc: 1.517  time: 0.3323  data_time: 0.0039  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 2.463  loss_cls: 0.01314  loss_box_reg: 0  loss_rpn_cls: 0.2508  loss_rpn_loc: 2.211  time: 0.3323  data_time: 0.0040  lr: 0.0001  max_mem: 10646M\n",
            "\u001b[32m[03/25 17:23:52 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:05:31 (0.3323 s / it)\n",
            "\u001b[32m[03/25 17:23:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:05:36 (0:00:05 on hooks)\n",
            "\u001b[32m[03/25 17:23:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]\n",
            "\u001b[32m[03/25 17:23:55 d2.data.common]: \u001b[0mSerializing 366 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/25 17:23:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/25 17:23:55 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "res = DefaultTrainer.test(cfg, model, evaluators=COCOEvaluator(\"birds_species_train\", output_dir=os.path.join(cfg.OUTPUT_DIR, \"inference\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR79fWQdG20E",
        "outputId": "df2452c6-3277-4173-b7a6-1a9a1f5fc30b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/25 17:34:17 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'birds_species_train' to COCO format ...\n",
            "\u001b[32m[03/25 17:34:17 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'birds_species_train' to COCO format ...)\n",
            "\u001b[32m[03/25 17:34:20 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[03/25 17:34:21 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 366, #annotations: 1510\n",
            "\u001b[32m[03/25 17:34:21 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/multibirds_densenet121/inference/birds_species_train_coco_format.json' ...\n",
            "\u001b[32m[03/25 17:34:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]\n",
            "\u001b[32m[03/25 17:34:24 d2.data.common]: \u001b[0mSerializing 366 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/25 17:34:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "\u001b[32m[03/25 17:34:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 366 batches\n",
            "\u001b[32m[03/25 17:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/366. Dataloading: 0.0067 s/iter. Inference: 0.1416 s/iter. Eval: 0.0007 s/iter. Total: 0.1490 s/iter. ETA=0:00:52\n",
            "\u001b[32m[03/25 17:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 49/366. Dataloading: 0.0029 s/iter. Inference: 0.1313 s/iter. Eval: 0.0005 s/iter. Total: 0.1348 s/iter. ETA=0:00:42\n",
            "\u001b[32m[03/25 17:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 88/366. Dataloading: 0.0025 s/iter. Inference: 0.1302 s/iter. Eval: 0.0004 s/iter. Total: 0.1332 s/iter. ETA=0:00:37\n",
            "\u001b[32m[03/25 17:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 126/366. Dataloading: 0.0023 s/iter. Inference: 0.1301 s/iter. Eval: 0.0004 s/iter. Total: 0.1329 s/iter. ETA=0:00:31\n",
            "\u001b[32m[03/25 17:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 162/366. Dataloading: 0.0025 s/iter. Inference: 0.1312 s/iter. Eval: 0.0004 s/iter. Total: 0.1343 s/iter. ETA=0:00:27\n",
            "\u001b[32m[03/25 17:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 200/366. Dataloading: 0.0024 s/iter. Inference: 0.1309 s/iter. Eval: 0.0004 s/iter. Total: 0.1339 s/iter. ETA=0:00:22\n",
            "\u001b[32m[03/25 17:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 238/366. Dataloading: 0.0024 s/iter. Inference: 0.1307 s/iter. Eval: 0.0004 s/iter. Total: 0.1337 s/iter. ETA=0:00:17\n",
            "\u001b[32m[03/25 17:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 275/366. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.0004 s/iter. Total: 0.1345 s/iter. ETA=0:00:12\n",
            "\u001b[32m[03/25 17:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 311/366. Dataloading: 0.0026 s/iter. Inference: 0.1321 s/iter. Eval: 0.0005 s/iter. Total: 0.1354 s/iter. ETA=0:00:07\n",
            "\u001b[32m[03/25 17:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 349/366. Dataloading: 0.0026 s/iter. Inference: 0.1318 s/iter. Eval: 0.0005 s/iter. Total: 0.1350 s/iter. ETA=0:00:02\n",
            "\u001b[32m[03/25 17:35:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.802117 (0.135186 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/25 17:35:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:47 (0.131770 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/25 17:35:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[03/25 17:35:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/multibirds_densenet121/inference/coco_instances_results.json\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category         | AP    | category                | AP    | category     | AP    |\n",
            "|:-----------------|:------|:------------------------|:------|:-------------|:------|\n",
            "| Brown Pelican    | 0.000 | Laughing Gull           | 0.000 | Mixed Tern   | 0.000 |\n",
            "| Great Blue Heron | nan   | Great Egret/White Morph | 0.000 | Unknown Bird | 0.000 |\n",
            "\u001b[32m[03/25 17:35:15 d2.engine.defaults]: \u001b[0mEvaluation results for birds_species_val in csv format:\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[03/25 17:35:15 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to figure out DefaultPredictor"
      ],
      "metadata": {
        "id": "d74nymvqJlcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(images[0])\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "klwTciLc6b14",
        "outputId": "b9dd2afa-64dc-4de8-9795-71b3ca4f7b22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b5de535fcb35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, original_image)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/transforms/transform.py\u001b[0m in \u001b[0;36mapply_image\u001b[0;34m(self, img, interp)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# PIL only supports uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'strides'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:"
      ],
      "metadata": {
        "id": "dgcrudY-ErG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "diZK_TgqErnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API."
      ],
      "metadata": {
        "id": "UNwNZZQzNQhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From tutorial\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"birds_species_val\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"birds_species_val\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "metadata": {
        "id": "iHZiOv97NYe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "c3a6e9c5-cdcc-4290-efae-fee69d8b042d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a4fa8b9691e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# From tutorial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"birds_species_val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"birds_species_val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team Audubon Fall 21 created the following functions for performance."
      ],
      "metadata": {
        "id": "87wJHM11RyAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "from Audubon_F21.utils.evaluation import plot_precision_recall\n",
        "from Audubon_F21.utils.evaluation import get_precisions_recalls\n",
        "\n",
        "print('validation inference:')\n",
        "val_precisions, val_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_species_val\")\n",
        "plot_precision_recall(val_precisions, val_max_recalls, BIRD_SPECIES + [\"Unknown Bird\"],\n",
        "                      BIRD_SPECIES_COLORS + [(0, 0, 0)])\n",
        "\n",
        "print('test inference:')\n",
        "test_precisions, test_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_species_test\")\n",
        "plot_precision_recall(test_precisions, test_max_recalls, BIRD_SPECIES + [\"Unknown Bird\"],\n",
        "                      BIRD_SPECIES_COLORS + [(0, 0, 0)])\n",
        "\n",
        "# Plot examples of detections on validation and testing tiled images \n",
        "for d in [\"val\", \"test\"]:\n",
        "    dataset_dicts = DatasetCatalog.get(f\"birds_species_{d}\")\n",
        "    metadata_set = MetadataCatalog.get(f\"birds_species_{d}\")\n",
        "    print(f'\\n {d} examples:')\n",
        "    for (i,k) in enumerate(random.sample(dataset_dicts, 2)):   # 2 samples\n",
        "        im = cv2.imread(k[\"file_name\"])\n",
        "        outputs = predictor(im)    # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "        outputs = outputs[\"instances\"].to(\"cpu\")\n",
        "        outputs = outputs[outputs.scores > 0.5]   # tutorial doesn't remove these; keep line?\n",
        "        v = Visualizer(im[:, :, ::-1],\n",
        "                        metadata=metadata_set,\n",
        "                        scale=0.5,\n",
        "                        instance_mode=ColorMode.SEGMENTATION)\n",
        "        out = v.draw_instance_predictions(outputs)\n",
        "        cv2.imshow(f'{d} prediction {i}',out.get_image()[:, :, ::-1])\n",
        "        cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "eR4O7L2iHaWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21f9893e-3710-416e-9094-342f9aea67c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation inference:\n",
            "\u001b[32m[03/18 19:12:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/18 19:12:56 d2.data.common]: \u001b[0mSerializing 366 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/18 19:12:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "\u001b[32m[03/18 19:12:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 366 batches\n",
            "\u001b[32m[03/18 19:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/366. Dataloading: 0.0017 s/iter. Inference: 0.1726 s/iter. Eval: 0.0001 s/iter. Total: 0.1745 s/iter. ETA=0:01:01\n",
            "\u001b[32m[03/18 19:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 40/366. Dataloading: 0.0021 s/iter. Inference: 0.1711 s/iter. Eval: 0.0001 s/iter. Total: 0.1734 s/iter. ETA=0:00:56\n",
            "\u001b[32m[03/18 19:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 69/366. Dataloading: 0.0024 s/iter. Inference: 0.1713 s/iter. Eval: 0.0001 s/iter. Total: 0.1739 s/iter. ETA=0:00:51\n",
            "\u001b[32m[03/18 19:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 98/366. Dataloading: 0.0024 s/iter. Inference: 0.1710 s/iter. Eval: 0.0001 s/iter. Total: 0.1736 s/iter. ETA=0:00:46\n",
            "\u001b[32m[03/18 19:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 126/366. Dataloading: 0.0031 s/iter. Inference: 0.1718 s/iter. Eval: 0.0001 s/iter. Total: 0.1751 s/iter. ETA=0:00:42\n",
            "\u001b[32m[03/18 19:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 156/366. Dataloading: 0.0029 s/iter. Inference: 0.1714 s/iter. Eval: 0.0001 s/iter. Total: 0.1745 s/iter. ETA=0:00:36\n",
            "\u001b[32m[03/18 19:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 186/366. Dataloading: 0.0027 s/iter. Inference: 0.1712 s/iter. Eval: 0.0001 s/iter. Total: 0.1741 s/iter. ETA=0:00:31\n",
            "\u001b[32m[03/18 19:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 216/366. Dataloading: 0.0026 s/iter. Inference: 0.1711 s/iter. Eval: 0.0001 s/iter. Total: 0.1739 s/iter. ETA=0:00:26\n",
            "\u001b[32m[03/18 19:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 246/366. Dataloading: 0.0025 s/iter. Inference: 0.1709 s/iter. Eval: 0.0001 s/iter. Total: 0.1737 s/iter. ETA=0:00:20\n",
            "\u001b[32m[03/18 19:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 275/366. Dataloading: 0.0024 s/iter. Inference: 0.1709 s/iter. Eval: 0.0001 s/iter. Total: 0.1736 s/iter. ETA=0:00:15\n",
            "\u001b[32m[03/18 19:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 305/366. Dataloading: 0.0024 s/iter. Inference: 0.1708 s/iter. Eval: 0.0001 s/iter. Total: 0.1734 s/iter. ETA=0:00:10\n",
            "\u001b[32m[03/18 19:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 334/366. Dataloading: 0.0024 s/iter. Inference: 0.1708 s/iter. Eval: 0.0001 s/iter. Total: 0.1735 s/iter. ETA=0:00:05\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 363/366. Dataloading: 0.0023 s/iter. Inference: 0.1708 s/iter. Eval: 0.0001 s/iter. Total: 0.1734 s/iter. ETA=0:00:00\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:02.657158 (0.173566 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:01 (0.170835 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[03/18 19:13:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            "AP50 for Brown Pelican: 0.0\n",
            "AP75 for Brown Pelican: 0.0\n",
            "Max recall (IoU 50) for Brown Pelican: 0.0\n",
            "AP50 for Laughing Gull: 0.0\n",
            "AP75 for Laughing Gull: 0.0\n",
            "Max recall (IoU 50) for Laughing Gull: 0.0\n",
            "AP50 for Mixed Tern: 0.0\n",
            "AP75 for Mixed Tern: 0.0\n",
            "Max recall (IoU 50) for Mixed Tern: 0.0\n",
            "AP50 for Great Blue Heron: -1.0\n",
            "AP75 for Great Blue Heron: -1.0\n",
            "Max recall (IoU 50) for Great Blue Heron: -1.0\n",
            "AP50 for Great Egret/White Morph: 0.0\n",
            "AP75 for Great Egret/White Morph: 0.0\n",
            "Max recall (IoU 50) for Great Egret/White Morph: 0.0\n",
            "AP50 for Unknown Bird: 0.0\n",
            "AP75 for Unknown Bird: 0.0\n",
            "Max recall (IoU 50) for Unknown Bird: 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mlc_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_foreground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_rgba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misRGBA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA values should be within 0-1 range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA values should be within 0-1 range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mlc_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_foreground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_rgba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misRGBA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA values should be within 0-1 range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA values should be within 0-1 range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mlc_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_foreground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_rgba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misRGBA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA values should be within 0-1 range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA values should be within 0-1 range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test inference:\n",
            "\u001b[32m[03/18 19:14:00 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'birds_species_test' to COCO format ...\n",
            "\u001b[32m[03/18 19:14:00 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'birds_species_test' to COCO format ...)\n",
            "\u001b[32m[03/18 19:14:03 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[03/18 19:14:03 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 366, #annotations: 1497\n",
            "\u001b[32m[03/18 19:14:03 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/birds_species_test_coco_format.json' ...\n",
            "\u001b[32m[03/18 19:14:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/18 19:14:07 d2.data.common]: \u001b[0mSerializing 366 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/18 19:14:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "\u001b[32m[03/18 19:14:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 366 batches\n",
            "\u001b[32m[03/18 19:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/366. Dataloading: 0.0017 s/iter. Inference: 0.1728 s/iter. Eval: 0.0001 s/iter. Total: 0.1746 s/iter. ETA=0:01:01\n",
            "\u001b[32m[03/18 19:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 39/366. Dataloading: 0.0038 s/iter. Inference: 0.1742 s/iter. Eval: 0.0001 s/iter. Total: 0.1783 s/iter. ETA=0:00:58\n",
            "\u001b[32m[03/18 19:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 68/366. Dataloading: 0.0032 s/iter. Inference: 0.1730 s/iter. Eval: 0.0001 s/iter. Total: 0.1766 s/iter. ETA=0:00:52\n",
            "\u001b[32m[03/18 19:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 97/366. Dataloading: 0.0027 s/iter. Inference: 0.1724 s/iter. Eval: 0.0001 s/iter. Total: 0.1755 s/iter. ETA=0:00:47\n",
            "\u001b[32m[03/18 19:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 126/366. Dataloading: 0.0025 s/iter. Inference: 0.1721 s/iter. Eval: 0.0001 s/iter. Total: 0.1749 s/iter. ETA=0:00:41\n",
            "\u001b[32m[03/18 19:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 156/366. Dataloading: 0.0024 s/iter. Inference: 0.1717 s/iter. Eval: 0.0001 s/iter. Total: 0.1743 s/iter. ETA=0:00:36\n",
            "\u001b[32m[03/18 19:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 185/366. Dataloading: 0.0023 s/iter. Inference: 0.1715 s/iter. Eval: 0.0001 s/iter. Total: 0.1740 s/iter. ETA=0:00:31\n",
            "\u001b[32m[03/18 19:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 215/366. Dataloading: 0.0023 s/iter. Inference: 0.1713 s/iter. Eval: 0.0001 s/iter. Total: 0.1738 s/iter. ETA=0:00:26\n",
            "\u001b[32m[03/18 19:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 244/366. Dataloading: 0.0022 s/iter. Inference: 0.1712 s/iter. Eval: 0.0001 s/iter. Total: 0.1737 s/iter. ETA=0:00:21\n",
            "\u001b[32m[03/18 19:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 273/366. Dataloading: 0.0022 s/iter. Inference: 0.1711 s/iter. Eval: 0.0001 s/iter. Total: 0.1736 s/iter. ETA=0:00:16\n",
            "\u001b[32m[03/18 19:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 302/366. Dataloading: 0.0022 s/iter. Inference: 0.1710 s/iter. Eval: 0.0001 s/iter. Total: 0.1735 s/iter. ETA=0:00:11\n",
            "\u001b[32m[03/18 19:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 331/366. Dataloading: 0.0022 s/iter. Inference: 0.1710 s/iter. Eval: 0.0001 s/iter. Total: 0.1735 s/iter. ETA=0:00:06\n",
            "\u001b[32m[03/18 19:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 360/366. Dataloading: 0.0022 s/iter. Inference: 0.1710 s/iter. Eval: 0.0001 s/iter. Total: 0.1735 s/iter. ETA=0:00:01\n",
            "\u001b[32m[03/18 19:15:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:02.686840 (0.173648 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/18 19:15:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:01 (0.171024 s / iter per device, on 1 devices)\n",
            "\u001b[32m[03/18 19:15:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[03/18 19:15:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[03/18 19:15:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
            "\u001b[32m[03/18 19:15:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[03/18 19:15:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            "AP50 for Brown Pelican: 0.0\n",
            "AP75 for Brown Pelican: 0.0\n",
            "Max recall (IoU 50) for Brown Pelican: 0.0\n",
            "AP50 for Laughing Gull: 0.0\n",
            "AP75 for Laughing Gull: 0.0\n",
            "Max recall (IoU 50) for Laughing Gull: 0.0\n",
            "AP50 for Mixed Tern: 0.0\n",
            "AP75 for Mixed Tern: 0.0\n",
            "Max recall (IoU 50) for Mixed Tern: 0.0\n",
            "AP50 for Great Blue Heron: -1.0\n",
            "AP75 for Great Blue Heron: -1.0\n",
            "Max recall (IoU 50) for Great Blue Heron: -1.0\n",
            "AP50 for Great Egret/White Morph: 0.0\n",
            "AP75 for Great Egret/White Morph: 0.0\n",
            "Max recall (IoU 50) for Great Egret/White Morph: 0.0\n",
            "AP50 for Unknown Bird: 0.0\n",
            "AP75 for Unknown Bird: 0.0\n",
            "Max recall (IoU 50) for Unknown Bird: 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mlc_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_foreground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_rgba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misRGBA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA values should be within 0-1 range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA values should be within 0-1 range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mlc_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_foreground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_rgba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misRGBA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA values should be within 0-1 range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA values should be within 0-1 range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mlc_rgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_foreground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_rgba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misRGBA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA values should be within 0-1 range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RGBA values should be within 0-1 range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " val examples:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7ce9c8469911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                         instance_mode=ColorMode.SEGMENTATION)\n\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_instance_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{d} prediction {i}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run on Test Set"
      ],
      "metadata": {
        "id": "LcoVq9W2TLfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tile the test set\n",
        "\n",
        "The tiling step in the detection pipeline is done using a sliding window. The sub-images are deliberately generated to have a significant proportion of overlapping with adjacent sub-images. We want to have the overlapping to ensure that there is at least one complete version of each bird in one of the sub-images. We then try to eliminate overlapping predicted bounding boxes for the same bird by using non-maximum suppression."
      ],
      "metadata": {
        "id": "Rwhnti2KTWN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Audubon_F21.utils.cropping import crop_dataset_img_only\n",
        "\n",
        "# create folder to contain tiled images\n",
        "!rm -rf './data/crop'\n",
        "!mkdir -p './data/crop'\n",
        "\n",
        "# perform tiling on images \n",
        "# data_dir = './data/raw'   # data directory folder \n",
        "data_dir = './data/split/test'\n",
        "output_dir = './data/crop'\n",
        "img_ext = '.JPG'\n",
        "CROP_WIDTH = 640 \n",
        "CROP_HEIGHT = 640\n",
        "SLIDING_SIZE = 400 \n",
        "crop_dataset_img_only(data_dir, img_ext, output_dir, crop_height=CROP_HEIGHT, crop_width=CROP_WIDTH, sliding_size=SLIDING_SIZE)"
      ],
      "metadata": {
        "id": "jtvLxOM5TOC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run pipeline"
      ],
      "metadata": {
        "id": "t33hz__vXt_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from Audubon_F21.utils.evaluation import evaluate_full_pipeline\n",
        "\n",
        "# create list of tiled images to be run predictor on \n",
        "eval_file_lst = []\n",
        "eval_file_lst = eval_file_lst + glob.glob('./data/crop/*.JPEG')\n",
        "\n",
        "# Create detectron2 config and predictor \n",
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model; tutorial uses 0.7\n",
        "\n",
        "# download model weights\n",
        "!gdown -q https://drive.google.com/uc?id=1-f_INg5D0yG7AJUkuSJUcIl6BSaf-smR    # currently previous team's weights\n",
        "# load model weights \n",
        "cfg.MODEL.WEIGHTS = \"./model_final.pth\"   # I'm assuming the downloaded weights were saved as 'model_final.pth'\n",
        "\n",
        "BIRD_SPECIES = [\"Brown Pelican\", \"Laughing Gull\", \"Mixed Tern\",\n",
        "                \"Great Blue Heron\",\"Great Egret/White Morph\"]   # not really used\n",
        "SPECIES_MAP = {0: 'Brown Pelican', 1: 'Laughing Gull', 2: 'Mixed Tern', 3: 'Great Blue Heron',\n",
        "               4: 'Great Egret/White Morph', 5: 'Other/Unknown'}\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES) \n",
        "\n",
        "# Create default predictor to run inference \n",
        "predictor = DefaultPredictor(cfg)\n",
        "RAW_IMG_WIDTH = 8192\n",
        "RAW_IMG_HEIGHT = 5460\n",
        "\n",
        "# Run evaluation \n",
        "output_df = evaluate_full_pipeline(eval_file_lst, predictor, SPECIES_MAP, RAW_IMG_WIDTH, RAW_IMG_HEIGHT,\n",
        "                           CROP_WIDTH, CROP_HEIGHT, SLIDING_SIZE)"
      ],
      "metadata": {
        "id": "5n1a-HWcXv6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download annotations as CSV file"
      ],
      "metadata": {
        "id": "47rfjZ1BX3qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "output_df.to_csv('output.csv')\n",
        "files.download('output.csv')"
      ],
      "metadata": {
        "id": "-z74qkrrX2sO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}