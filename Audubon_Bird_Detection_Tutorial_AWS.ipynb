{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwP9RpOZ21zr"
   },
   "source": [
    "# AWS bird detection\n",
    "\n",
    "We thank F21 semesters student's for the base code\n",
    "\n",
    "Authors: Wenbin Li\n",
    "\n",
    "This jupyter notebook is meant to run on AWS sagemaker studio. All the file location should be on S3 bucket or any other bucket service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj5EpyIO21Fp"
   },
   "source": [
    "## Installation and setup for Colab\n",
    "\n",
    "Run the next cells to setup Colab with the necessary requirements. We clone the Github repo with the developed code, and install dependencies, namely Detectron2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (0.17.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.13.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (8.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.19.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.2.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (5.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3PFNsJ_Tek3A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Import useful libraries\n",
    "import os, sys, shutil, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from skimage import io  \n",
    "from datetime import datetime\n",
    "from distutils.dir_util import copy_tree\n",
    "import boto3\n",
    "import seaborn as sns\n",
    "from tqdm.autonotebook import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import random\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZK9R5DgH2jBr"
   },
   "outputs": [],
   "source": [
    "# This cell only excecutes if you're running on Colab. \n",
    "# if 'google.colab' in sys.modules:\n",
    "#   from google.colab import drive \n",
    "#   drive.mount('/gdrive/') # Mount Google Drive! \n",
    "\n",
    "  # Clone Audubon bird detection Github repo \n",
    "#   !git clone https://github.com/RiceD2KLab/Audubon_F21.git \n",
    "\n",
    "  # Install dependencies \n",
    "  !pip install -qq pyyaml==5.1\n",
    "  # This is the current pytorch version on Colab. Uncomment this if Colab changes its pytorch version\n",
    "  !pip install -qq torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "  # Install detectron2 that matches the above pytorch version\n",
    "  # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "  !pip install -qq detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
    "  # exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n",
    "\n",
    "  !pip install -qq wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHHm2ikxC99D"
   },
   "source": [
    "## Data exploration & wrangling\n",
    "\n",
    "The following cells contain the data exploration and wrangling modules of the data science pipeline. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9m81HuKnD-J8"
   },
   "source": [
    "### Load dataset from Google Drive \n",
    "\n",
    "The following cell unzips a folder stored on Google Drive ontop the Colab machine. You can modify this cell to load your drone images onto the Colab instance! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = boto3.resource('s3')\n",
    "# for bucket in s3.buckets.all():\n",
    "#     print(bucket.name)\n",
    "    \n",
    "# my_bucket = 'sagemaker-studio-zd1j05seaof'\n",
    "# my_file = '1017_1/DJI_20210520122305_0032.JPG'\n",
    "# s3client = boto3.client('s3')\n",
    "# response = s3client.get_object(Bucket=my_bucket, Key=my_file)\n",
    "# body = response['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# im = Image.open(body)\n",
    "# image = np.array(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (20,10))\n",
    "# plt.imshow(image[500:1300, 500:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to load up the file path for the annotation\n",
    "my_bucket = 'sagemaker-studio-zd1j05seaof'\n",
    "conn = boto3.client('s3')\n",
    "annot_path = 'annotation_1017/'\n",
    "annot = conn.list_objects(Bucket=my_bucket, Prefix=annot_path)['Contents']\n",
    "# for f in annot:\n",
    "# #     print(f['Key']) # print what files are in this specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation_1017/DJI_20210520122305_0032.bbx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot[1]['Key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA32BBX_JX-r"
   },
   "source": [
    "### Data exploration on AWS\n",
    "\n",
    "The following cells generate some metrics and plots to help understand the loaded dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3client = boto3.client('s3')\n",
    "target_data = []\n",
    "for f in annot:\n",
    "    response = s3client.get_object(Bucket=my_bucket, Key=f['Key'])\n",
    "    body = response['Body']\n",
    "    target_data.append(pd.read_csv(body, header=0, \n",
    "                       names = [\"class_id\", \"class_name\", \"x\", \"y\", \"width\", \"height\"] ))\n",
    "target_data = pd.concat(target_data, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bird Species Distribution\n",
      "Laughing Gull Adult       772\n",
      "Mixed Tern Adult          286\n",
      "Mixed Tern Flying          19\n",
      "Laughing Gull Flying       17\n",
      "Other Bird                 16\n",
      "Trash/Debris               13\n",
      "Brown Pelican Adult         5\n",
      "Brown Pelican Juvenile      1\n",
      "Name: class_name, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target_data\n",
    "print('\\n Bird Species Distribution')\n",
    "print(target_data[\"class_name\"].value_counts())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = target_data[\"class_name\"].value_counts().plot.bar(figsize=(10,6))  \n",
    "ax.set_title('Bird Species Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotation_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-86d12874dce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# key_exist(my_bucket, 'annotation_1017/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mannotation_lst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'annotation_lst' is not defined"
     ]
    }
   ],
   "source": [
    "# key_exist(my_bucket, 'annotation_1017/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchKey",
     "evalue": "An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cfa61dbeb27c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcropping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv_to_dict_AWS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mannot_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_to_dict_AWS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmy_bucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'annotation_1017/DJI_20210520121104_0601.bbx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1017_2/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mannotation_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Audubon_F21/utils/cropping.py\u001b[0m in \u001b[0;36mcsv_to_dict_AWS\u001b[0;34m(bucket_name, key, im_fold, AWS_storage, annot_file_ext)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0ms3client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAWS_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "# from PIL import Image \n",
    "from PIL import Image\n",
    "from utils import plotting\n",
    "from utils.cropping import csv_to_dict_AWS\n",
    "\n",
    "annot_dict = csv_to_dict_AWS(bucket_name= my_bucket,key = 'annotation_1017/DJI_20210520121104_0601.bbx', im_fold = '1017_2/')\n",
    "annotation_lst = [list(x.values()) for x in annot_dict['bbox']]\n",
    "\n",
    "imre = s3client.get_object(Bucket = my_bucket, Key= '1017_2/DJI_20210520121104_0601.JPG' )\n",
    "im = Image.open(imre['Body'])\n",
    "\n",
    "print(\"Raw image with bounding boxes:\")\n",
    "plotting.plot_img_bbx(im, annotation_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x['Key'] for x in s3client.list_objects_v2(Bucket = my_bucket, Prefix = '1017_2/')['Contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1srbJOyFEA9u"
   },
   "source": [
    "### Tiling \n",
    "\n",
    "In order to prepare the dataset to be used for training in our deep learning models, we must tile the large 8192 × 5460 raw drone images into smaller sizes. The size of generated images can be specified by setting parameters and is default to be 640 × 640.\n",
    "\n",
    "The following cells tiles the original dataset images and corresponding annotations in annotation files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the key/directory exist in the S3 bucket\n",
    "# a key can be the folder location or the file name\n",
    "def key_exist(my_bucket, my_key, s3 = 's3'):\n",
    "    # sujective to change for the bucket placement\n",
    "    s3_client = boto3.client(s3)\n",
    "    response = s3_client.list_objects_v2(Bucket=my_bucket, Prefix=my_key,MaxKeys=1)\n",
    "    \n",
    "    return 'Contents' in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3client.put_object(Bucket = my_bucket, Key = 'Test123/') #this is how to make a new director in S3 bucket\n",
    "# im.save('./temp'+'/123.JPEG')\n",
    "# s3client.upload_file(Filename='./temp/123.JPEG', Bucket = my_bucket, Key = 'Test123/123.JPEG') #this is how to upload a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_csv_AWS(info_dict, output_path, empty):\n",
    "    \"\"\"\n",
    "    Function to convert (cropped images') info_dicts to annoatation csv files\n",
    "    INPUT:\n",
    "     info_dict -- output from the csv_to_dict function, containing bbox, filename, img_size\n",
    "     output_path -- folder path to store the converted csv files\n",
    "    OUTPUT:\n",
    "      an csv file(corresponding for 1 image) saved to a folder. The bndbox info in the format of (className,\n",
    "      xmin, ymin, width, height)\n",
    "    \"\"\"\n",
    "    new_bbx_buffer = []\n",
    "    schema = ['class_id', 'desc', 'x', 'y', 'width', 'height']\n",
    "    if not empty:\n",
    "        for obj in info_dict['bbox']:\n",
    "            className = obj['class']\n",
    "            desc = obj['desc']\n",
    "            xmin = obj['xmin']\n",
    "            xmax = obj['xmax']\n",
    "            ymin = obj['ymin']\n",
    "            ymax = obj['ymax']\n",
    "            # className, description, xmin, ymin, width, height\n",
    "            new_bbx_buffer.append([className, desc, int(xmin), int(ymin), int(xmax) - int(xmin), int(ymax) - int(ymin)])\n",
    "    # Name of the file to save\n",
    "    save_file_name = os.path.join('./temp', info_dict[\"file_name\"].replace('JPG', 'csv'))\n",
    "    \n",
    "    \n",
    "    # write to files\n",
    "    with open(save_file_name, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([g for g in schema])\n",
    "        if not empty:\n",
    "            writer.writerows(new_bbx_buffer)\n",
    "            \n",
    "    #Write it to the cloud\n",
    "    s3client.upload_file(Filename = save_file_name, Bucket = my_bucket, Key = output_key +'/'+info_dict[\"file_name\"].replace('JPG', 'csv'))\n",
    "\n",
    "def tile_annot(left, right, top, bottom, info_dict, i, j, crop_height, crop_width, overlap, file_dict):\n",
    "    \"\"\"\n",
    "    THIS FUNCTION calculate the new positions of bndbox in cropped img and append them to file_dict,\n",
    "    which is an info dict for that cropped img.\n",
    "\n",
    "    INPUTS:\n",
    "    left, right, top, bottom -- params for the python crop img function, coordinates for tiles.\n",
    "    origin is top left.\n",
    "    info_dict -- the info_dict we get from the csv_to_dict function.\n",
    "    overlap -- threshold for keeping a bbox.\n",
    "    \"\"\"\n",
    "    # file_dict stores info of one subimage as a dictionary. keys indicate original file name and subimage position.\n",
    "    file_dict[str(i) + '_' + str(j)] = {}\n",
    "    file_dict[str(i) + '_' + str(j)]['bbox'] = []\n",
    "    file_dict[str(i) + '_' + str(j)]['file_name'] = info_dict['file_name'][:-4] + '_' + str(i) + '_' + str(j) + '.JPG'\n",
    "    file_dict[str(i) + '_' + str(j)]['img_size'] = (right - left, bottom - top, 3)\n",
    "\n",
    "    valid = False\n",
    "    for b in info_dict['bbox']:\n",
    "        ymin = max(b['ymin'] - top, 0)\n",
    "        ymax = min(b['ymax'] - top, crop_height)\n",
    "        xmin = max(b['xmin'] - left, 0)\n",
    "        xmax = min(b['xmax'] - left, crop_width)\n",
    "        # if the bird is not in this patch, pass\n",
    "        if xmin > crop_width or xmax < 0 or ymin > crop_height or ymax < 0:\n",
    "            continue\n",
    "        else:\n",
    "            if (xmax - xmin) * (ymax - ymin) > overlap * (b['xmax'] - b['xmin']) * (b['ymax'] - b['ymin']) \\\n",
    "                    or b['xmin'] >= left and b['xmax'] <= right and b['ymin'] >= top and b['ymax'] <= bottom:\n",
    "                valid = True\n",
    "                # instance_dict is the info_dict for one patch\n",
    "                instance_dict = {}\n",
    "                # transform bbx coordinates\n",
    "                instance_dict['class'] = b['class']\n",
    "                instance_dict['desc'] = b['desc']\n",
    "                instance_dict['xmin'] = max(b['xmin'] - left, 0)\n",
    "                instance_dict['xmax'] = min(b['xmax'] - left, crop_width)\n",
    "                instance_dict['ymin'] = max(b['ymin'] - top, 0)\n",
    "                instance_dict['ymax'] = min(b['ymax'] - top, crop_height)\n",
    "\n",
    "                file_dict[str(i) + '_' + str(j)]['bbox'].append(instance_dict)\n",
    "    return valid\n",
    "\n",
    "\n",
    "# this function generates all the cropped images and all corresponding label txt files for a single file\n",
    "# file_dict stores cropped images info dict in one dictionary.\n",
    "def crop_img_AWS(s3client, my_bucket, annot_key, img_key, output_key, crop_height, crop_width, class_map = {}, overlap=0.2, annot_file_ext='csv', file_dict={}):\n",
    "    \"\"\"\n",
    "    This function crops one image and output corresponding labels.\n",
    "    Currently, this function generates the cropped images AND the corresponding csv files to output_dir\n",
    "    INPUT:\n",
    "    crop_height, crop_weight -- desired patch size.\n",
    "    overlap -- threshold for keeping bbx.\n",
    "    annot_file_ext -- annotation file extension\n",
    "    \"\"\"\n",
    "    print(img_key)\n",
    "    print(annot_key)\n",
    "    info_dict = csv_to_dict_AWS(bucket_name= my_bucket,key = annot_key, im_fold = img_key)\n",
    "    \n",
    "    img_height, img_width, img_depth = info_dict['img_size']\n",
    "    \n",
    "    image = s3client.get_object(Bucket = my_bucket, Key= img_key + annot_key.split('/')[-1].replace(annot_file_ext, 'JPG') )\n",
    "    \n",
    "    im = Image.open(image['Body'], 'r')\n",
    "    \n",
    "    file_name = annot_key.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # go through the image from top left corner\n",
    "    for i in range(img_height // crop_height + 1):\n",
    "\n",
    "        for j in range(img_width // crop_width + 1):\n",
    "\n",
    "            if j < (img_width // crop_width) and i < (img_height // crop_height):\n",
    "                left = j * crop_width\n",
    "                right = (j + 1) * crop_width\n",
    "                top = i * crop_height\n",
    "                bottom = (i + 1) * crop_height\n",
    "\n",
    "            elif j == img_width // crop_width and i < (img_height // crop_height):\n",
    "                left = img_width - crop_width\n",
    "                right = img_width\n",
    "                top = i * crop_height\n",
    "                bottom = (i + 1) * crop_height\n",
    "\n",
    "            # if rectangles left on edges, take subimage of crop_height*crop_width by taking a part from within.\n",
    "            elif i == img_height // crop_height and j < (img_width // crop_width):\n",
    "                left = j * crop_width\n",
    "                right = (j + 1) * crop_width\n",
    "                top = img_height - crop_height\n",
    "                bottom = img_height\n",
    "\n",
    "            else:\n",
    "                left = img_width - crop_width\n",
    "                right = img_width\n",
    "                top = img_height - crop_height\n",
    "                bottom = img_height\n",
    "                \n",
    "            # even if no birds in cropped img, keep the cropped image\n",
    "            \n",
    "            if tile_annot(left, right, top, bottom, info_dict, i, j, crop_height, crop_width, overlap, file_dict):\n",
    "                # print('Generating segmentation at position: ', left, top, right, bottom)\n",
    "                \n",
    "                c_img = im.crop((left, top, right, bottom))\n",
    "                c_img_name = file_name + '_' + str(i) + '_' + str(j) +'.JPEG'\n",
    "                \n",
    "                # write all this is the temporary folder in the current working directory\n",
    "                c_img.save('./temp'+'/'+c_img_name)\n",
    "                \n",
    "                #uploading it to the bucket storage\n",
    "                s3client.upload_file(Filename = './temp'+'/'+c_img_name, Bucket = my_bucket, Key = output_key +'/'+c_img_name)\n",
    "                \n",
    "                \n",
    "\n",
    "    # output the file_dict to a folder of csv files containing labels for each cropped file\n",
    "    for b in file_dict:\n",
    "        if file_dict[b]['bbox'] == []:\n",
    "            empty = True\n",
    "            continue\n",
    "        else:\n",
    "            empty = False\n",
    "            dict_to_csv_AWS(file_dict[b], empty=empty, output_path=output_key)\n",
    "\n",
    "    return file_dict\n",
    "\n",
    "\n",
    "def crop_dataset_AWS(bucket, data_key, output_key, annot_key, annot_file_ext = 'csv', class_map = {}, crop_height=640, crop_width=640):\n",
    "    \"\"\"\n",
    "    :param data_dir: image set directory\n",
    "    :param output_dir: output directory\n",
    "    :param annot_file_ext: annotation file extension\n",
    "    :param crop_height: image height after tiling, default 640\n",
    "    :param crop_width: image width after tiling, default 640\n",
    "    \"\"\"\n",
    "    s3client = boto3.client('s3') # start grabbing or makign directory in S3 bucket\n",
    "    \n",
    "    \n",
    "    if not key_exist(my_bucket = bucket, my_key = output_key): # this function works only for S3 bucket, will change if we need to modularize this\n",
    "        print(f\"Creating output directory at in S3 bucket called: {output_key}\")\n",
    "        s3client.put_object(Bucket = bucket, Key = output_key)\n",
    "        \n",
    "    # making temporary folder in the current directory\n",
    "    if not os.path.exists('./temp'):\n",
    "        print(f\"Creating temp folder\")\n",
    "        os.makedirs('./temp')\n",
    "\n",
    "                            \n",
    "\n",
    "    # find all the files inside the annotated folders                            \n",
    "    if annot_file_ext == 'csv':\n",
    "        files = [x['Key'] for x in s3client.list_objects_v2(Bucket = my_bucket, Prefix = annot_key)['Contents']]\n",
    "    if annot_file_ext == 'bbx':\n",
    "        files = [x['Key'] for x in s3client.list_objects_v2(Bucket = my_bucket, Prefix = annot_key)['Contents']]\n",
    "                            \n",
    "                            \n",
    "    # for each annotated file, crop the image and place it into the output directory\n",
    "    for f in tqdm(files, desc='Cropping files'):\n",
    "        crop_img_AWS(s3client = s3client, my_bucket = bucket, annot_key=f ,img_key = data_key, output_key = output_key, crop_height=crop_height, crop_width=crop_width, class_map=class_map,\n",
    "                 annot_file_ext=annot_file_ext)\n",
    "    \n",
    "    shutil.rmtree('./temp')\n",
    "    return None\n",
    "#     \n",
    "\n",
    "\n",
    "# def crop_dataset_AWS(bucket, data_key, output_key, annot_file_ext = 'csv', class_map = {}, crop_height=640, crop_width=640):\n",
    "#     \"\"\"\n",
    "#     :param data_dir: image set directory\n",
    "#     :param output_dir: output directory\n",
    "#     :param annot_file_ext: annotation file extension\n",
    "#     :param crop_height: image height after tiling, default 640\n",
    "#     :param crop_width: image width after tiling, default 640\n",
    "#     \"\"\"\n",
    "#     s3client = boto3.client('s3') # start grabbing or makign directory in S3 bucket\n",
    "    \n",
    "    \n",
    "#     if not key_exist(my_bucket = bucket, my_key = output_key): # this function works only for S3 bucket, will change if we need to modularize this\n",
    "#         print(f\"Creating output directory at in S3 bucket called: {output_key}\")\n",
    "#         s3client.put_object(Bucket = bucket, Key = output_key)\n",
    "#         s3client.put_object(Bucket = bucket, Key = output_key+'Intermediate/')\n",
    "#     elif not key_exist(my_bucket = bucket, my_key = output_key +'Intermediate/'):\n",
    "#         s3client.put_object(Bucket = bucket, Key = output_key+'Intermediate/')\n",
    "        \n",
    "#     # making temporary folder in the current directory\n",
    "#     if not os.path.exists('./temp'):\n",
    "#         print(f\"Creating temp folder\")\n",
    "#         os.makedirs('./temp')\n",
    "#         os.makedirs(os.path.join('./temp', 'Intermediate'))\n",
    "#     elif not os.path.exists(os.path.join('./temp', 'Intermediate')):\n",
    "#         os.makedirs(os.path.join('./temp', 'Intermediate'))\n",
    "\n",
    "                            \n",
    "\n",
    "#     # find all the files inside the annotated folders                            \n",
    "#     if annot_file_ext == 'csv':\n",
    "#         files = [data_key+Prex['Key'] for x in s3client.list_objects_v2(Bucket = my_bucket, Prefix = data_key)['Contents']]\n",
    "#     if annot_file_ext == 'bbx':\n",
    "#         files = [data_key+Prex['Key'] for x in s3client.list_objects_v2(Bucket = my_bucket, Prefix = data_key)['Contents']]\n",
    "                            \n",
    "                            \n",
    "#     # for each annotated file, crop the image and place it into the output directory\n",
    "#     for f in tqdm(files, desc='Cropping files'):\n",
    "#         crop_img_AWS(s3client = s3client, my_buckey = bucket, annot_key=f,img_key = data_key, crop_height=crop_height, crop_width=crop_width, output_key=output_key, class_map=class_map,\n",
    "#                  annot_file_ext=annot_file_ext)\n",
    "\n",
    "#     shutil.rmtree(os.path.join(output_dir, 'Intermediate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GfSuT1ioQFOX"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8bc069241c4bc2823417c7c2be928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cropping files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017_1/\n",
      "annotation_1017/DJI_20210520122304_0031.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122305_0032.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122307_0033.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122309_0034.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122418_0076.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122420_0077.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122422_0078.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122423_0079.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122425_0080.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122427_0081.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122503_0103.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122504_0104.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122506_0105.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122508_0106.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122509_0107.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122511_0108.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122513_0109.bbx\n",
      "1017_1/\n",
      "annotation_1017/DJI_20210520122515_0110.bbx\n"
     ]
    }
   ],
   "source": [
    "# from Audubon_F21.utils.cropping import crop_dataset\n",
    "\n",
    "# # data_dir is the path that contains both images and annotations (image: jpg; annotation: csv or bbx)\n",
    "# data_dir = './data/raw' # data directory folder \n",
    "# # output dir is the path where you want to output new files. Please use the folder you defined above.\n",
    "# output_dir = './data/tiled'\n",
    "\n",
    "data_key = '1017_1/'\n",
    "output_key = 'test_crop/'\n",
    "annot_key = 'annotation_1017/'\n",
    "\n",
    "crop_dataset_AWS(bucket = my_bucket, data_key = data_key, output_key=output_key\n",
    "                 , annot_key = annot_key, annot_file_ext = 'bbx',crop_height=640, crop_width=640)\n",
    "\n",
    "# crop_dataset(data_dir, output_dir, annot_file_ext = 'bbx', crop_height = 640, crop_width = 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split_AWS(file_dir, output_dir, train_frac=0.8, val_frac=0.1):\n",
    "    \"\"\"\n",
    "    :param file_dir: crop_dataset()'s output path:\n",
    "    :param output_dir: an empty folder\n",
    "    :param train_frac: fraction for training\n",
    "    :param val_frac: fraction for validation, 1-train-val will be fraction for test\n",
    "    \"\"\"\n",
    "    p = Path(output_dir)\n",
    "    p1 = Path(os.path.join(output_dir, 'train'))\n",
    "    p2 = Path(os.path.join(output_dir, 'val'))\n",
    "    p3 = Path(os.path.join(output_dir, 'test'))\n",
    "\n",
    "    if not p.is_dir():\n",
    "        print('The output directory should be an empty folder')\n",
    "    if not p1.is_dir():\n",
    "        print('Please create an empty folder named \"train\" inside the output folder')\n",
    "    if not p2.is_dir():\n",
    "        print('Please create an empty folder named \"val\" inside the output folder')\n",
    "    if not p3.is_dir():\n",
    "        print('Please create an empty folder named \"test\" inside the output folder')\n",
    "\n",
    "    img_list = [f for f in os.listdir(file_dir) if f[-4:] == 'JPEG']\n",
    "    random.Random(4).shuffle(img_list)\n",
    "    csv_list = [f.replace('JPEG', 'csv') for f in img_list]\n",
    "    size = len(img_list)\n",
    "    train_sz = int(size * train_frac)\n",
    "    val_sz = int(size * val_frac)\n",
    "    for idx in range(size):\n",
    "        if idx < train_sz:\n",
    "            shutil.move(os.path.join(file_dir, img_list[idx]), os.path.join(output_dir, 'train'))\n",
    "            shutil.move(os.path.join(file_dir, csv_list[idx]), os.path.join(output_dir, 'train'))\n",
    "        elif idx < train_sz + val_sz:\n",
    "            shutil.move(os.path.join(file_dir, img_list[idx]), os.path.join(output_dir, 'val'))\n",
    "            shutil.move(os.path.join(file_dir, csv_list[idx]), os.path.join(output_dir, 'val'))\n",
    "        else:\n",
    "            shutil.move(os.path.join(file_dir, img_list[idx]), os.path.join(output_dir, 'test'))\n",
    "            shutil.move(os.path.join(file_dir, csv_list[idx]), os.path.join(output_dir, 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H0_4KdPEEJZ"
   },
   "source": [
    "### Split dataset into training, validation, and test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfb8Q6BtQQ5F"
   },
   "outputs": [],
   "source": [
    " from Audubon_F21.utils.cropping import train_val_test_split\n",
    "\n",
    "# create a new output folder for train, val, test dataset\n",
    "# create three folders under the new output folder, with name 'train', 'val', 'test'\n",
    "!mkdir -p /content/data/split\n",
    "!mkdir -p /content/data/split/train\n",
    "!mkdir -p /content/data/split/val\n",
    "!mkdir -p /content/data/split/test\n",
    "\n",
    "# specify the folder directory where you have the tiled images (output_dir of the crop_dataset() function)\n",
    "file_dir = '/content/data/tiled'\n",
    "# output_dir is the new output folder you created in the cell above\n",
    "output_dir = '/content/data/split'\n",
    "# train is a percentage, the fraction of files for training\n",
    "train_frac = 0.8\n",
    "# val is a percentage, the fraction of files for validation\n",
    "val_frac = 0.1\n",
    "# the fraction for test is default to be 1-train-val\n",
    "train_val_test_split(file_dir, output_dir, train_frac=train_frac, val_frac=val_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gEL7rjsEsSk"
   },
   "outputs": [],
   "source": [
    "# Distribution of bird species for train, val, and test sets\n",
    "# data directory folders \n",
    "data_dir = 'data/split'\n",
    "dirs = [d for d in os.listdir(data_dir)]\n",
    "\n",
    "# Load CSV files \n",
    "for d in dirs: \n",
    "  target_data = []\n",
    "  for f in glob.glob(os.path.join(data_dir,d,'*.csv')): \n",
    "    target_data.append(pd.read_csv(f, header=0, \n",
    "                              names = [\"class_id\", \"class_name\", \"x\", \"y\", \"width\", \"height\"]) )\n",
    "  target_data = pd.concat(target_data, axis=0, ignore_index=True)\n",
    "\n",
    "  # Visualize dataset \n",
    "  print(f'\\n {d} - Bird Species Distribution')\n",
    "  print(target_data[\"class_name\"].value_counts())\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_moYO6MEsyq"
   },
   "source": [
    "## Modeling \n",
    "\n",
    "The primary models used to detect birds within the drone images are convolutional neural network (CNN) based object detectors. To implement these models, we utilize [Detectron2](https://github.com/facebookresearch/detectron2), Facebook AI Research's next generation library that provides state-of-the-art detection and segmentation algorithms. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yU-y99FBF7nm"
   },
   "source": [
    "### Setup dataloaders \n",
    "\n",
    "The following cell registers the training, validation, and testing datasets with Detectron2's dataset catalogs. Note that we register both a version that utilizes both a singular \"bird-only\" label and the bird species labels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5ruFu59cxbp"
   },
   "outputs": [],
   "source": [
    "from Audubon_F21.utils.dataloader import register_datasets\n",
    "\n",
    "data_dir = './data/split'\n",
    "img_ext='.JPEG'\n",
    "dirs = [os.path.join(data_dir,d) for d in os.listdir(data_dir)]\n",
    "\n",
    "# Bird species used by object detector. Species contained in dataset that are \n",
    "# not contained in this list will be categorized as an \"Unknown Bird\"\n",
    "BIRD_SPECIES = [\"Brown Pelican\", \"Laughing Gull\", \"Mixed Tern\",\n",
    "                \"Great Blue Heron\",\"Great Egret/White Morph\"]\n",
    "\n",
    "# Bounding box colors for bird species (used when plotting images)\n",
    "BIRD_SPECIES_COLORS = [(255,0,0), (255,153,51), (0, 255, 0), \n",
    "                       (0,0,255), (255, 51, 255)]\n",
    "\n",
    "register_datasets(dirs,img_ext,BIRD_SPECIES,bird_species_colors=BIRD_SPECIES_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVGJPdoKF-mj"
   },
   "source": [
    "### Training \n",
    "\n",
    "The following cells train a RetinaNet and Faster R-CNN model with a ResNet-50 FPN backbone. The model weights are initialized from a model pretrained on the MS COCO dataset. The training loop is based on Detectron2's Default Trainer.  Hyperparameters can be tweaked! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq7HuVsoKQET"
   },
   "source": [
    "#### Bird-only model\n",
    "\n",
    "The bird-only model simplies localizes all birds and does not distiguish bird species. We utilize RetinaNet for faster performance rather than accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7pAw0SSKkh5"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from Audubon_F21.utils.trainer import Trainer\n",
    "\n",
    "# setup training logger \n",
    "setup_logger()\n",
    "\n",
    "model_name = \"retinanet_R_50_FPN_1x\"\n",
    "\n",
    "# Create detectron2 config \n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{model_name}.yaml\"))\n",
    "# Get pretrained model from MS COCO\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{model_name}.yaml\")\n",
    "\n",
    "# add datasets used for training and validation \n",
    "cfg.DATASETS.TRAIN = (\"birds_only_train\",)\n",
    "cfg.DATASETS.TEST = (\"birds_only_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 1e-3 # pick a good LR\n",
    "cfg.SOLVER.GAMMA = 0.1 # pick a good LR\n",
    "cfg.SOLVER.WARMUP_ITERS = 1\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 1\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.SOLVER.STEPS = [500,]\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "\n",
    "cfg.OUTPUT_DIR = f\"./output/multibirds_{model_name}\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# train on bird species\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfDQZrLuKkn_"
   },
   "source": [
    "#### Bird species \n",
    "\n",
    "The bird species model both localizes and classifies bird species. We registered the species to be classifed in the above dataloader (see BIRD_SPECIES list). We utilize Faster R-CNN for better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmB4XbGUdI0u"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from Audubon_F21.utils.trainer import Trainer\n",
    "\n",
    "# setup training logger \n",
    "setup_logger()\n",
    "\n",
    "model_name = \"faster_rcnn_R_50_FPN_1x\"\n",
    "\n",
    "# Create detectron2 config \n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{model_name}.yaml\"))\n",
    "# Get pretrained model from MS COCO\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{model_name}.yaml\")\n",
    "\n",
    "# add datasets used for training and validation \n",
    "cfg.DATASETS.TRAIN = (\"birds_species_train\",)\n",
    "cfg.DATASETS.TEST = (\"birds_species_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 1e-3 # pick a good LR\n",
    "cfg.SOLVER.GAMMA = 0.1 # pick a good LR\n",
    "cfg.SOLVER.WARMUP_ITERS = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES)\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.SOLVER.STEPS = [500,]\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "\n",
    "cfg.OUTPUT_DIR = f\"./output/multibirds_{model_name}\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# train on bird species\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8liZIl4GCvV"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "The following cell outputs various evaluation metrics, plots, and images. Please read more about the [COCO evaluation metrics](https://cocodataset.org/#detection-eval) to understand how the AP metrics are calculated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE1OYaOPKf1s"
   },
   "source": [
    "#### Bird-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oi41HGjtKf-_"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from Audubon_F21.utils.evaluation import plot_precision_recall\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"./output/bird_only_retinanet_R_50_FPN_1x/model_final.pth\" # path to the model we just trained\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "print('validation inference:')\n",
    "val_precisions, val_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_only_val\")\n",
    "plot_precision_recall(val_precisions, val_max_recalls, [\"Bird\"])\n",
    "\n",
    "print('test inference:')\n",
    "test_precisions, test_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_only_test\")\n",
    "plot_precision_recall(test_precisions, test_max_recalls, [\"Bird\"])\n",
    "\n",
    "# Plot examples of detections on validation and testing tiled images \n",
    "for d in [\"val\", \"test\"]:\n",
    "    dataset_dicts = DatasetCatalog.get(f\"birds_only_{d}\")\n",
    "    print(f'\\n {d} examples:')\n",
    "    for k in random.sample(dataset_dicts, 2):\n",
    "        im = cv2.imread(k[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        outputs = outputs[\"instances\"].to(\"cpu\")\n",
    "        outputs = outputs[outputs.scores > 0.5]\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                        metadata=MetadataCatalog.get(f\"birds_only_{d}\"),\n",
    "                        scale=0.5)\n",
    "        out = v.draw_instance_predictions(outputs)\n",
    "        cv2.imshow(f'{d} prediction {i}',out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmrAC_sTKd77"
   },
   "source": [
    "#### Bird species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkypxNYPqUW3"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from Audubon_F21.utils.evaluation import plot_precision_recall\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"./output/multibirds_faster_rcnn_R_50_FPN_1x/model_final.pth\" # path to the model we just trained\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "print('validation inference:')\n",
    "val_precisions, val_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_species_val\")\n",
    "plot_precision_recall(val_precisions, val_max_recalls, BIRD_SPECIES + [\"Unknown Bird\"],\n",
    "                      BIRD_SPECIES_COLORS + [(0, 0, 0)])\n",
    "\n",
    "print('test inference:')\n",
    "test_precisions, test_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_species_test\")\n",
    "plot_precision_recall(test_precisions, test_max_recalls, BIRD_SPECIES + [\"Unknown Bird\"],\n",
    "                      BIRD_SPECIES_COLORS + [(0, 0, 0)])\n",
    "\n",
    "# Plot examples of detections on validation and testing tiled images \n",
    "for d in [\"val\", \"test\"]:\n",
    "    dataset_dicts = DatasetCatalog.get(f\"birds_species_{d}\")\n",
    "    print(f'\\n {d} examples:')\n",
    "    for k in random.sample(dataset_dicts, 2):\n",
    "        im = cv2.imread(k[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        outputs = outputs[\"instances\"].to(\"cpu\")\n",
    "        outputs = outputs[outputs.scores > 0.5]\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                        metadata=MetadataCatalog.get(f\"birds_species_{d}\"),\n",
    "                        scale=0.5,\n",
    "                        instance_mode=ColorMode.SEGMENTATION)\n",
    "        out = v.draw_instance_predictions(outputs)\n",
    "        cv2.imshow(f'{d} prediction {i}',out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjFXDR2GFvG6"
   },
   "source": [
    "## Running trained model on dataset\n",
    "\n",
    "The following cells run a pretrained model on a dataset containing only raw images. It generates an output csv file containing the predicted bounding boxes after non-maximal suppression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVOe51dbBIgs"
   },
   "source": [
    "### Tiling\n",
    "\n",
    "The tiling step in the detection pipeline is done using a sliding window. The sub-images are deliberately generated to have a significant proportion of overlapping with adjacent sub-images. The level of overlapping can be specified by setting a parameter. The reason why we want to have the overlapping is because we can ensure that there is at least one complete version of each bird in one of the sub-images. We then try to eliminate overlapping predicted bounding boxes for the same bird by using non-maximum suppression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMbdS6L3Elbr"
   },
   "outputs": [],
   "source": [
    "from Audubon_F21.utils.cropping import crop_dataset_img_only\n",
    "\n",
    "# create folder to contain tiled images\n",
    "!rm -rf './data/crop'\n",
    "!mkdir -p './data/crop'\n",
    "\n",
    "# perform tiling on images \n",
    "data_dir = './data/raw' # data directory folder \n",
    "output_dir = './data/crop'\n",
    "img_ext = '.JPG'\n",
    "CROP_WIDTH = 640 \n",
    "CROP_HEIGHT = 640\n",
    "SLIDING_SIZE = 400 \n",
    "crop_dataset_img_only(data_dir, img_ext, output_dir, crop_height=CROP_HEIGHT, crop_width=CROP_WIDTH, sliding_size=SLIDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoowvdjRBK1w"
   },
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K62BnBAi9_EN"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from Audubon_F21.utils.evaluation import evaluate_full_pipeline\n",
    "\n",
    "# create list of tiled images to be run predictor on \n",
    "eval_file_lst = []\n",
    "eval_file_lst = eval_file_lst + glob.glob('./data/crop/*.JPEG')\n",
    "\n",
    "# Create detectron2 config and predictor \n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# download model weights\n",
    "!gdown -q https://drive.google.com/uc?id=1-f_INg5D0yG7AJUkuSJUcIl6BSaf-smR \n",
    "# load model weights \n",
    "cfg.MODEL.WEIGHTS = \"./model_final.pth\"\n",
    "\n",
    "BIRD_SPECIES = [\"Brown Pelican\", \"Laughing Gull\", \"Mixed Tern\",\n",
    "                \"Great Blue Heron\",\"Great Egret/White Morph\"]\n",
    "SPECIES_MAP = {0: 'Brown Pelican', 1: 'Laughing Gull', 2: 'Mixed Tern', 3: 'Great Blue Heron',\n",
    "               4: 'Great Egret/White Morph', 5: 'Other/Unknown'}\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES) \n",
    "\n",
    "# Create default predictor to run inference \n",
    "predictor = DefaultPredictor(cfg)\n",
    "RAW_IMG_WIDTH = 8192\n",
    "RAW_IMG_HEIGHT = 5460\n",
    "\n",
    "# Run evaluation \n",
    "output_df = evaluate_full_pipeline(eval_file_lst, predictor, SPECIES_MAP, RAW_IMG_WIDTH, RAW_IMG_HEIGHT,\n",
    "                           CROP_WIDTH, CROP_HEIGHT, SLIDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDetAeyFBPtP"
   },
   "source": [
    "### Download annotations as CSV file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrBccu--38Ho"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "output_df.to_csv('output.csv')\n",
    "files.download('output.csv') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMtFjtOerH5KNQRHS/Mz6hg",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Audubon-Bird-Detection-Tutorial.ipynb",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
