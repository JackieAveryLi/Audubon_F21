{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiceD2KLab/Audubon_F21/blob/SP22/Sp22_Audubon_Bird_Detection_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwP9RpOZ21zr"
      },
      "source": [
        "# 2022 Spring Houston Audubon Bird Detection Tutorial \n",
        "Authors: Raul Garcia, Jiahui Yu, Dhananjay Singh Vijay Singh, Tianjiao Yu, Maojie Tang, Wenbin Li\n",
        "\n",
        "This is a colab tutorial of how to perform the data science pipelien for 10 bird detection for object detection and classification from drone images. This work is in collaboration with the Houston Audubon organization. Note: this tutorial expects an already cropped and splitted of the images into Train, Test and Validation folders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj5EpyIO21Fp"
      },
      "source": [
        "## Installation and setup for Colab\n",
        "\n",
        "Run the next cells to setup Colab with the necessary requirements. We clone the Github repo with the developed code, and install dependencies, namely Detectron2. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3PFNsJ_Tek3A"
      },
      "outputs": [],
      "source": [
        "# Import the basic libraries needed to run the code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import os, json, cv2, random\n",
        "import sys, shutil, glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage import io  \n",
        "from datetime import datetime\n",
        "from distutils.dir_util import copy_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK9R5DgH2jBr"
      },
      "outputs": [],
      "source": [
        "# This cell only excecutes if you're running on Colab. \n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import drive \n",
        "  drive.mount('/gdrive/') # Mount Google Drive! \n",
        "\n",
        "  ################ Clone Audubon bird detection Github repo SP22 branch\n",
        "  !git clone -b SP22 https://github.com/RiceD2KLab/Audubon_F21.git\n",
        "\n",
        "  # Install dependencies \n",
        "  !pip install -qq pyyaml==5.1\n",
        "  # This is the current pytorch version on Colab. Uncomment this if Colab changes its pytorch version\n",
        "  !pip install -qq torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "  # Install detectron2 that matches the above pytorch version\n",
        "  # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "  !pip install -qq detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "  # exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n",
        "\n",
        "  !pip install -qq wandb\n",
        "\n",
        "  # For AWS\n",
        "  !pip install boto3\n",
        "  # importing the hyperparameter tuning package\n",
        "  ! pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m81HuKnD-J8"
      },
      "source": [
        "### Load dataset from Google Drive \n",
        "\n",
        "This cell is an example to load pre split data into google colabs. Here we unzip google images from an example google drive and place them into Train, Test, Validation folders. This can be adapted for any drone images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra1KJejrGdbn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p './data'\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# downloading a presplitted dataset. This can be changed to any datasets but the folders must be named: Validate, Train, Test\n",
        "!gdown -q https://drive.google.com/uc?id=1qmVP-zSK7Ew2QsjitAE2rFK5GwqRJcGR\n",
        "!unzip -q './Validate.zip' -d './data'\n",
        "!gdown -q https://drive.google.com/uc?id=1QzppZTelUfoxVFCh_eOEgp19PPsuYnCl\n",
        "!unzip -q './Train.zip' -d './data'\n",
        "!gdown -q https://drive.google.com/uc?id=1DAW8uAYJGhNFdFzDozs9GjiyVPBlK-3h\n",
        "!unzip -q './Test.zip' -d './data'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Wrangling and Data Exploration\n",
        "\n",
        "Converting the bbx files into csv readable files. The bbx files is the default annotation files for the ground truth."
      ],
      "metadata": {
        "id": "OZIAywSeFW8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naming for the data directory\n",
        "crop_dir = './data'\n",
        "dirs = os.listdir(crop_dir)\n",
        "\n",
        "from Audubon_F21.utils.cropping import csv_to_dict, dict_to_csv\n",
        "\n",
        "# converting the bbx files into csv files and addeding it to the data directories\n",
        "for d in dirs:\n",
        "    for f in glob.glob(os.path.join(crop_dir, d, '*.bbx')):\n",
        "        dict_bird = csv_to_dict(f, annot_file_ext='bbx')\n",
        "        dict_to_csv(dict_bird, os.path.split(f)[0], empty=False, img_ext='bbx')"
      ],
      "metadata": {
        "id": "IZV5mkAeFVcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff3ce76-effb-4321-a531-21b0ca224612"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Audubon_F21/utils/cropping.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA32BBX_JX-r"
      },
      "source": [
        "### Data Exploration \n",
        "\n",
        "The following cells generate some metrics and plots to help understand the loaded dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76vawPkMJmu_"
      },
      "outputs": [],
      "source": [
        "# This cell plots the distribution of bird species contained in the entire dataset\n",
        "\n",
        "# print the distribution of birds in each class\n",
        "for d in dirs:\n",
        "    target_data = []\n",
        "    # grab all the annotation\n",
        "    for f in glob.glob(os.path.join(crop_dir, d, '*.csv')):\n",
        "        target_data.append(pd.read_csv(f, header=0,\n",
        "                                       names=[\"class_id\", \"class_name\", \"x\", \"y\", \"width\", \"height\"]))\n",
        "    target_data = pd.concat(target_data, axis=0, ignore_index=True)\n",
        "\n",
        "    # Visualize dataset\n",
        "    print(f'\\n {d} - Bird Species Distribution')\n",
        "    print(target_data[\"class_name\"].value_counts())\n",
        "    print('\\n')\n",
        "    # plotting the distributation\n",
        "    ax = target_data[\"class_name\"].value_counts().plot.bar(x=\"Bird Species\", y=\"Frequency\",figsize=(10,6))  \n",
        "    ax.set_title('Bird Species Distribution for '+ d +' set')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj_VoOC3Jg4A"
      },
      "outputs": [],
      "source": [
        "# Show an example image of 640x640 with corresponding bounding boxes \n",
        "\n",
        "\n",
        "from PIL import Image \n",
        "from Audubon_F21.utils import plotting\n",
        "from Audubon_F21.utils.cropping import csv_to_dict \n",
        "\n",
        "annot_dict = csv_to_dict(csv_path = './data/Test/102741 00008.bbx', annot_file_ext='bbx')\n",
        "annotation_lst = [list(x.values()) for x in annot_dict['bbox']]\n",
        "\n",
        "image_file = './data/Test/102741 00008.JPG'\n",
        "assert os.path.exists(image_file)\n",
        "\n",
        "#Load the image\n",
        "image = Image.open(image_file)\n",
        "\n",
        "#Plot the Bounding Box\n",
        "print(\"Raw image with bounding boxes:\")\n",
        "plotting.plot_img_bbx(image, annotation_lst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srbJOyFEA9u"
      },
      "source": [
        "### Perform data augmentation\n",
        "\n",
        "Targeting the low count species and increasing the count by peroforming data augmentation. The allowed image augmentation is flipping, rotating and contrast changing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfSuT1ioQFOX"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from Audubon_F21.utils.augmentation import AugTrainingSet, dataset_aug\n",
        "\n",
        "# # dst_dir is the folder of training data(only after cropping)\n",
        "dst_dir = crop_dir + '/Train'\n",
        "# aug_dir is where we put image after doing data augmentation\n",
        "os.makedirs('./temp', exist_ok=True)\n",
        "aug_dir = './temp'\n",
        "#\n",
        "# # Minimum portion of a bounding box being accepted in a subimage\n",
        "overlap = 0.2\n",
        "#\n",
        "# # List of species that we want to augment (PLEASE include the full name)\n",
        "minor_species = [\"REEGA\",\"WHIBA\",\"ROSPA\", \"BRPEA\", \"TRHEA\"]\n",
        "#\n",
        "# # Threshold of non-minor creatures existing in a subimage\n",
        "thres = .3\n",
        "\n",
        "#[horizontal filp, vertical flip, left rotate, right rotate, [brightness/contrast tunning, number of images produced]]\n",
        "aug_command = [1,1,1,0,[1,2]]\n",
        "\n",
        "dataset_aug(dst_dir, aug_dir, minor_species, overlap, thres,\n",
        "            aug_command, img_ext = 'JPG',annot_file_ext='csv',crop_height=640, crop_width=640)\n",
        "\n",
        "aug_list = glob.glob(os.path.join(aug_dir, '*'))\n",
        "\n",
        "# putting the augmented images into the original data directories\n",
        "for i in aug_list:\n",
        "    shutil.copy2(i, dst_dir)  # copy files from aug_list(certain files in aug_dir) to dst_dir (train data set)\n",
        "    # print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_moYO6MEsyq"
      },
      "source": [
        "# Modeling \n",
        "\n",
        "The primary models used to for object detection and classification from done images is Faster Region-Based Convolutional Neural Network (FASTER-RCNN). To implement this we utilized [Detectron2](https://github.com/facebookresearch/detectron2.git). This is Facebook research package. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU-y99FBF7nm"
      },
      "source": [
        "### Registering the dataset into Detectron2 \n",
        "\n",
        "The following cell registers the training, validation, and testing datasets with Detectron2's dataset catalogs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "K5ruFu59cxbp"
      },
      "outputs": [],
      "source": [
        "from Audubon_F21.utils.dataloader import register_datasets\n",
        "\n",
        "data_dir = crop_dir\n",
        "img_ext = '.JPG'\n",
        "dirs = [os.path.join(data_dir, d) for d in os.listdir(data_dir)]\n",
        "\n",
        "# Bird species used by object detector. Species contained in dataset that are\n",
        "# not contained in this list will be categorized as an \"Unknown Bird\"\n",
        "BIRD_SPECIES = ['BRPEA', 'LAGUA','MTRNA','TRHEA', 'BLSKA',\n",
        "                'BCNHA', 'REEGA', 'WHIBA', 'ROSPA',\n",
        "                'GBHEA']\n",
        "\n",
        "SPECIES_MAP = {0: 'BRPEA', 1: 'LAGUA', 2: 'MTRNA',\n",
        "               3: 'TRHEA', 4: 'BLSKA', 5:'BCNHA',\n",
        "               6: 'REEGA', 7: 'WHIBA', 8: 'ROSPA', 9: 'GBHEA'}\n",
        "\n",
        "\n",
        "# Bounding box colors for bird species (used when plotting images)\n",
        "BIRD_SPECIES_COLORS = []\n",
        "\n",
        "# register the datatset into Detectron2 category\n",
        "register_datasets(dirs, img_ext, BIRD_SPECIES, bird_species_colors=BIRD_SPECIES_COLORS, unknown_bird_category=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVGJPdoKF-mj"
      },
      "source": [
        "### Training \n",
        "\n",
        "The following cells train a Faster R-CNN model with ResNet-50 FPN as backbone. The model wieghts are from MS COCO dataset. A bayesian hyperparameter optimization scheme is implemented to fine the best learning rate and decay rate. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfDQZrLuKkn_"
      },
      "source": [
        "#### Bird species \n",
        "\n",
        "The bird species model both localizes and classifies bird species. We registered the species to be classifed in the above dataloader (see BIRD_SPECIES list). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the hyperparameter tuning package\n",
        "! pip install optuna"
      ],
      "metadata": {
        "id": "X76uDcRhXtJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmB4XbGUdI0u"
      },
      "outputs": [],
      "source": [
        "from Audubon_F21.utils.hyperparameter import main_hyper, main_fit\n",
        "\n",
        "# training the bird species model using Faster R-CNN\n",
        "custom_weight = []\n",
        "\n",
        "#name of the model output\n",
        "model_output_dir = './Training_models/04_28_10class_aug_T2'\n",
        "\n",
        "# model parameters\n",
        "cfg_parms = {'NUM_WORKERS': 0, 'IMS_PER_BATCH': 6, 'BASE_LR': .001, 'GAMMA': 0.01,\n",
        "             'WARMUP_ITERS': 1, 'MAX_ITER': 800,\n",
        "             'STEPS': [499], 'CHECKPOINT_PERIOD': 499, 'output_dir': model_output_dir,\n",
        "             'model_name': \"faster_rcnn_R_50_FPN_1x\", 'BIRD_SPECIES': BIRD_SPECIES, 'Custom': False}\n",
        "\n",
        "# hyperparameter tunning\n",
        "tuned_cfg_params = main_hyper(cfg_parms, iterations=2)\n",
        "\n",
        "# after tunning, grab the best model and train on for an additional 100 iteration\n",
        "tuned_cfg_params['MAX_ITER'] = tuned_cfg_params['MAX_ITER'] + 100\n",
        "tune_weight_dir, loss = main_fit(tuned_cfg_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8liZIl4GCvV"
      },
      "source": [
        "# Evaluation of the model\n",
        "\n",
        "The following cell outputs the evaluation metrics for IoU threshold of 0.5. Here the metrics are, precision recall curve, average precision, and confusion matrix and classification report. Please read more about the [COCO evaluation metrics](https://cocodataset.org/#detection-eval) to understand how the AP metrics are calculated. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for example only: loading a pretrained weight from \n",
        "!gdown -q https://drive.google.com/uc?id=1mpwtjrvYWi0u0jONtUf8FnTZbJfFDwVU\n",
        "!unzip -q './example_model.zip' -d './example_model'\n",
        "\n",
        "# this if you dont want to run the full training and would just want to see an example of an fitted model\n",
        "tune_weight_dir = './example_model/faster_rcnn_R_50_FPN_1x-20220402-174351'"
      ],
      "metadata": {
        "id": "Q1hQkwZeJmPc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the precision recall curves"
      ],
      "metadata": {
        "id": "xyyZ_LSFQGVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkypxNYPqUW3"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from Audubon_F21.utils.evaluation import plot_precision_recall\n",
        "from Audubon_F21.utils.evaluation import get_precisions_recalls\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "\n",
        "# Create detectron2 config and predictor\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3  # set threshold for this model\n",
        "\n",
        "# the trained model weights\n",
        "cfg.MODEL.WEIGHTS = os.path.join(tune_weight_dir, 'model_final.pth')\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 0\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES)\n",
        "cfg.OUTPUT_DIR = tune_weight_dir\n",
        "\n",
        "# Create default predictor to run inference\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# printing the precision and recall curves for each of the bird species with an IoU of 0.5\n",
        "print('test inference:')\n",
        "val_precisions, val_max_recalls = get_precisions_recalls(cfg, predictor, \"birds_species_Test\")\n",
        "plot_precision_recall(val_precisions, val_max_recalls, BIRD_SPECIES,\n",
        "                      BIRD_SPECIES_COLORS + [(0, 0, 0)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the confusion matrix"
      ],
      "metadata": {
        "id": "VxjFicyugZ5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Audubon_F21.utils.dataloader import get_bird_species_dicts\n",
        "from detectron2.data import DatasetCatalog\n",
        "from Audubon_F21.utils.confusion_matrix_birds import confusion_matrix_report\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# registering the test dataset\n",
        "d = 1\n",
        "\n",
        "# grabbing the test dataset\n",
        "data = DatasetCatalog.get(\"birds_species_Test\")\n",
        "\n",
        "# grab the confusion matrix\n",
        "pred_total, truth_total = confusion_matrix_report(data, predictor, BIRD_SPECIES, img_ext='JPG')\n",
        "\n",
        "# confusion matrix and classification report\n",
        "print(confusion_matrix(truth_total, pred_total))\n",
        "print(classification_report(truth_total, pred_total, target_names= BIRD_SPECIES+[\"Not Detected\"]))"
      ],
      "metadata": {
        "id": "gcXIKYfzgYCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjFXDR2GFvG6"
      },
      "source": [
        "# Performance Object detection on a new dataset\n",
        "\n",
        "Here, we are grabbing an example dataset of an 8k resolution drone image. We grab this dataset and running it through the model that we had just trainned. The export is an csv file which includes the bounding box and the class that was predicted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVOe51dbBIgs"
      },
      "source": [
        "### Tiling\n",
        "\n",
        "The tiling step in the detection pipeline is done using a sliding window. The sub-images are deliberately generated to have a significant proportion of overlapping with adjacent sub-images. The level of overlapping can be specified by setting a parameter. The reason why we want to have the overlapping is because we can ensure that there is at least one complete version of each bird in one of the sub-images. We then try to eliminate overlapping predicted bounding boxes for the same bird by using non-maximum suppression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMbdS6L3Elbr"
      },
      "outputs": [],
      "source": [
        "from Audubon_F21.utils.cropping import crop_dataset_img_only\n",
        "\n",
        "#downloading an example dataset\n",
        "!gdown -q https://drive.google.com/uc?id=1nrJNxeblB25RnRxOIFABelGusPFSe93a\n",
        "!unzip -q './QC.zip' -d './QC_image'\n",
        "\n",
        "\n",
        "# # perform tiling on images 8K images\n",
        "data_dir = './QC_image/QC'  # data directory folder\n",
        "os.makedirs(os.getcwd() + '/AI_QC_test/crop', exist_ok=True)\n",
        "output_dir = os.getcwd() + '/AI_QC_test/crop'\n",
        "img_ext = '.JPG'\n",
        "CROP_WIDTH = 640\n",
        "CROP_HEIGHT = 640\n",
        "SLIDING_SIZE = 400\n",
        "# performing the cropping of full resolution images\n",
        "crop_dataset_img_only(data_dir, img_ext, output_dir, crop_height=CROP_HEIGHT, crop_width=CROP_WIDTH,\n",
        "                      sliding_size=SLIDING_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoowvdjRBK1w"
      },
      "source": [
        "### Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K62BnBAi9_EN"
      },
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from Audubon_F21.utils.evaluation import evaluate_full_pipeline\n",
        "\n",
        "# create list of tiled images to be run predictor on \n",
        "eval_file_lst = []\n",
        "eval_file_lst = eval_file_lst + glob.glob('./AI_QC_test/crop/*.JPEG')\n",
        "\n",
        "# Create detectron2 config and predictor\n",
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3  # set threshold for this model\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(tune_weight_dir, 'model_final.pth')\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 0\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(BIRD_SPECIES)\n",
        "cfg.OUTPUT_DIR = tune_weight_dir\n",
        "\n",
        "# Create default predictor to run inference\n",
        "predictor = DefaultPredictor(cfg)\n",
        "RAW_IMG_WIDTH = 8192\n",
        "RAW_IMG_HEIGHT = 5460\n",
        "\n",
        "# Run evaluation \n",
        "output_df = evaluate_full_pipeline(eval_file_lst, predictor, SPECIES_MAP, RAW_IMG_WIDTH, RAW_IMG_HEIGHT,\n",
        "                           CROP_WIDTH, CROP_HEIGHT, SLIDING_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDetAeyFBPtP"
      },
      "source": [
        "### Download annotations as CSV file \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrBccu--38Ho"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "output_df.to_csv('output.csv')\n",
        "files.download('output.csv') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3Imlk14bgVhR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sp22 Audubon-Bird-Detection-Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
